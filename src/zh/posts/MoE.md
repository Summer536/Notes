---
title: MoE
date: 2025-07-31
readingTime: 300
category:
  - 笔记
# cover: /assets/images/cover3.jpg
isOriginal: true
---

# MoE：混合专家模型

## 简介

本文将讲解MoE的原理和实现。

<!-- more -->

## 一、摘要





## 总结


## 待更新

## 参考资料

1. [DeepSpeed-Megatron MoE并行训练（原理篇）](https://zhuanlan.zhihu.com/p/681154742)

