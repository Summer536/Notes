---
title: Flashattention
date: 2025-05-21
readingTime: 600
category:
  - æœºå™¨å­¦ä¹ 
  - æ·±åº¦å­¦ä¹ 
  - ç¬”è®°
tag:
  - æ³¨æ„åŠ›æœºåˆ¶
  - GPUä¼˜åŒ–
  - å¤§æ¨¡å‹
  - ç®—æ³•ä¼˜åŒ–
# cover: /assets/images/cover3.jpg
isOriginal: true
---

# Flashattention

## ç®€ä»‹

Flashattentionæ˜¯ä¸€ç§é«˜æ•ˆçš„æ³¨æ„åŠ›æœºåˆ¶è®¡ç®—æ–¹æ³•ï¼Œç”±æ–¯å¦ç¦å¤§å­¦ç ”ç©¶å›¢é˜Ÿåœ¨2022å¹´æå‡ºã€‚å®ƒé€šè¿‡ä¼˜åŒ–GPUå†…å­˜è®¿é—®æ¨¡å¼ï¼Œæ˜¾è‘—æé«˜äº†Transformeræ¨¡å‹ä¸­æ³¨æ„åŠ›è®¡ç®—çš„é€Ÿåº¦å¹¶é™ä½äº†å†…å­˜ä½¿ç”¨ã€‚ä½œä¸ºå¤§æ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„å…³é”®ä¼˜åŒ–æŠ€æœ¯ï¼ŒFlashattentionå·²è¢«å¹¿æ³›åº”ç”¨äºå„ç§å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ã€‚

<!-- more -->

## ä¸€ã€Flashattention-V1

### 1.1 æ ‡å‡†æ³¨æ„åŠ›æœºåˆ¶
ç»™å®šè¾“å…¥äºŒç»´çŸ©é˜µ $Q, K, V \in \mathbb{R}^{N \times d}$ï¼Œå…¶ä¸­ $N$ æ˜¯è¾“å…¥åºåˆ—çš„é•¿åº¦ï¼Œ$d$ æ˜¯è‡ªæ³¨æ„åŠ›æœºåˆ¶å¤´çš„é•¿åº¦ã€‚Softmax æ˜¯æŒ‰è¡Œåº”ç”¨çš„ï¼Œæ³¨æ„åŠ›è¾“å‡ºçŸ©é˜µ $O \in \mathbb{R}^{N \times d}$ çš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼š
$$
\begin{align*}
S &= Q K^\mathrm{T} \in \mathbb{R}^{N \times N}, \quad
P = \text{softmax}(S) \in \mathbb{R}^{N \times N}, \quad
O = P V \in \mathbb{R}^{N \times d}.
\end{align*}
$$
![](Figure/flashattention/FAV1_0.png)
æ ‡å‡†çš„ Attention è¿ç®—å¤§è‡´å¯ä»¥æè¿°ä¸ºä»¥ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š
- å°† Q,K çŸ©é˜µä»¥å—çš„å½¢å¼ä» HBM ä¸­åŠ è½½åˆ° SRAM ä¸­ï¼Œè®¡ç®— S=QK ï¼Œå°† S å†™å…¥åˆ° HBM ä¸­ã€‚
- å°† S çŸ©é˜µä» HBM ä¸­åŠ è½½åˆ° SRAM ä¸­ï¼Œè®¡ç®— P=Softmax(S) ï¼Œå°† P å†™å…¥åˆ° HBM ä¸­ã€‚
- å°† P,V çŸ©é˜µä»¥å—çš„å½¢å¼ä» HBM ä¸­åŠ è½½åˆ° SRAM ä¸­ï¼Œè®¡ç®— O=PV ï¼Œå°† O å†™å…¥åˆ° HBM ä¸­ã€‚

![](Figure/flashattention/FAV1_2.png)

self-attention ç®—å­æ¶‰åŠåˆ°çš„å’Œ HBM æ•°æ®ä¼ è¾“è¿‡ç¨‹å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œå¾ˆæ˜æ˜¾éœ€è¦ä» HBM ä¸­è¯»å– 5 æ¬¡ï¼Œå†™å…¥ HBM 3 æ¬¡ï¼ŒHBM è®¿å­˜é‡ $MAC = 4N^2 + 3Nd$ï¼Œå¾ˆæ˜æ˜¾æ ‡å‡†æ³¨æ„åŠ›çš„ HBM è®¿é—®ä»£ä»· $MAC$ éšåºåˆ—é•¿åº¦å¢åŠ å‘ˆäºŒæ¬¡æ–¹å¢é•¿ã€‚

è€Œ self-attention çš„è®¡ç®—é‡ä¸º $4N^2d+N^2$ï¼Œæ ‡å‡†æ³¨æ„åŠ›ç®—å­çš„æ“ä½œå¼ºåº¦ $= \frac{4N^2d+N^2}{4N^2 + 3Nd}$ã€‚å…¬å¼å¯çœ‹å‡ºï¼Œæ ‡å‡†æ³¨æ„åŠ›ç®—å­æ˜¯ä¸€ä¸ªå¾ˆæ˜æ˜¾çš„å†…å­˜å—é™å‹ç®—å­ã€‚
![](Figure/flashattention/MACandFlops.png)

### 1.2 FAV1æ•´ä½“ä»‹ç»

#### æŒ‘æˆ˜
åœ¨Flash Attentionå‡ºæ¥ä¹‹å‰ï¼Œå·²ç»æœ‰äº†å¾ˆå¤šäº†fusedattentionç®—å­ï¼Œä½†æ˜¯ä»”ç»†çœ‹ï¼Œå¯ä»¥å‘ç°è¿™å…¶å®ä¸æ˜¯çœŸæ­£çš„èåˆç®—å­ï¼Œåªæ˜¯æŠŠmatmul kernelã€scale kernelã€softmax kernelçš„æ¥å£åœ¨ä¸€ä¸ªfusedattentionç®—å­é‡Œé¢æŒ‰ç…§è®¡ç®—é¡ºåºè°ƒäº†ä¸€ä¸‹ï¼Œè¿™ç§æ‰‹æ³•æœ€å¤šå‡å°‘äº†pytorchã€TFç­‰æ¡†æ¶å¯¹ç®—å­çš„è°ƒåº¦å¼€é”€ï¼Œå…¶å®ä¸èƒ½çœŸæ­£è§£å†³å¯¹HBMæˆ–è€…æ˜¾å­˜çš„memory trafficã€‚

**èåˆMHAçš„æŒ‘æˆ˜åœ¨äºä¸¤ç‚¹ï¼š**

1.è§£å†³softmaxï¼Œå› ä¸ºsoftmaxæ˜¯ä¸€ä¸ªrow-wiseï¼ˆä»¥è¡Œä¸ºå•ä½ï¼‰çš„æ“ä½œï¼Œå¿…é¡»è¦éå†softmaxä¸€è¡Œæ‰èƒ½å¾—åˆ°ç»“æœï¼Œç”±æ­¤ï¼Œåé¢çš„matmulä¸å¾—ä¸ç­‰å¾…è¿™ä¸ªè¿‡ç¨‹ï¼Œå¯¼è‡´å¹¶è¡Œæ€§é™ä½

2.åœ¨å¯„å­˜å™¨å’Œshared memoryå¤ç”¨æ•°æ®åšè®¡ç®—ï¼Œè€Œä¸æ˜¯å»HBMæˆ–æ˜¾å­˜ä¸Šå»è¯»æ•°æ®æ¥è®¡ç®—ï¼Œç„¶è€Œå¯„å­˜å™¨æ•°é‡å’Œshared memory (ä¹Ÿå°±æ˜¯å›¾ä¸­çš„SRAM) å¤§å°éƒ½æœ‰é™ï¼Œåœ¨å·¦å›¾çš„æƒ…å†µä¸‹ï¼Œæ˜¾ç„¶æ— æ³•å°†softmaxçš„ç»“æœå­˜åˆ°è¿™ä¸¤ä¸ªå­˜å‚¨å•å…ƒé‡Œé¢ä¾›ä¸‹ä¸€ä¸ªmatmulå¤ç”¨ï¼Œä¸‹ä¸€ä¸ªmatmulä¸å¾—ä¸å»HBMæˆ–æ˜¾å­˜ä¸Šè¯»æ•°æ®

![](Figure/flashattention/FAV1_6.png)

#### æ•´ä½“æ€æƒ³
FAV1ç®—æ³•æ•´ä½“åšåˆ°äº†å¦‚ä¸‹çš„ä¸¤éƒ¨åˆ†ï¼š
- Tilingï¼ˆåœ¨å‰å‘å’Œåå‘ä¼ é€’ä¸­ä½¿ç”¨ï¼‰:
  1. ï¼ˆè§£å†³æŒ‘æˆ˜1ï¼‰Online Softmax å®ç°åœ¨ä¸€ä¸ª for å¾ªç¯ä¸­è®¡ç®— 
$m_i$ å’Œ $d_i$ ï¼Œ**FlashAttention-v1 åŸºäºå®ƒçš„æ€æƒ³æ›´è¿›ä¸€æ­¥ï¼Œå®ç°åœ¨ä¸€ä¸ª for å¾ªç¯ä¸­è®¡ç®— $m_i$ ã€$d_i$ å’Œæ³¨æ„åŠ›è¾“å‡º $O_i$ ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨ä¸€ä¸ª kernel ä¸­å®ç° attention çš„æ‰€æœ‰æ“ä½œ**ã€‚

  2. ï¼ˆè§£å†³æŒ‘æˆ˜2ï¼‰å†**é€šè¿‡åˆ†å— Tiling æŠ€æœ¯**ï¼Œå°†è¾“å…¥çš„ Qã€Kã€V çŸ©é˜µæ‹†åˆ†ä¸ºå¤šä¸ªå—ï¼Œå°†å…¶ä»è¾ƒæ…¢çš„ HBM åŠ è½½åˆ°æ›´å¿«çš„ SRAM ä¸­ï¼Œä»è€Œå¤§å¤§å‡å°‘äº† HBM è®¿é—®æ¬¡æ•°ï¼ˆå†…å­˜è¯»/å†™çš„æ¬¡æ•°ï¼‰ï¼Œç„¶ååˆ†åˆ«è®¡ç®—è¿™äº›å—çš„æ³¨æ„åŠ›è¾“å‡ºï¼Œæœ€åï¼Œå°†æ¯ä¸ªå—çš„è¾“å‡ºæŒ‰æ­£ç¡®çš„å½’ä¸€åŒ–å› å­ç¼©æ”¾ä¹‹åç›¸åŠ åå¯å¾—åˆ°ç²¾ç¡®çš„æ³¨æ„åŠ›è¾“å‡ºã€‚
- é‡æ–°è®¡ç®—ï¼ˆä»…åœ¨åå‘ä¼ é€’ä¸­ä½¿ç”¨ï¼‰:æ ¸å¿ƒæ€æƒ³ä¸ºä¸ä¸ºåå‘ä¼ é€’å­˜å‚¨Sã€PçŸ©é˜µï¼Œä½†æ˜¯è¾“å‡ºsoftmaxçš„lå’Œmï¼Œåœ¨åå‘ä¼ æ’­æ—¶ï¼Œé‡æ–°è®¡ç®—Sã€PçŸ©é˜µã€‚

### 1.3 FAV1ç®—æ³•æµç¨‹

<!-- ![](Figure/flashattention/FAV1_1.png "FlashAttention Block Diagram") -->
<!-- <p align="center">
  <img src="Figure/FA1.png" width="500" alt="æ ¸å¿ƒæ€æƒ³"/>
</p> -->
Flashattentionæ€»ä½“çš„ç®—æ³•æµç¨‹å›¾å¦‚ä¸‹ï¼š
![](Figure/flashattention/FAV1_5.png)

---
1. è®¾ç½®å—çš„è¡Œå¤§å° $B_r = \frac{M}{4d}$ï¼Œå—çš„åˆ—å¤§å°ä¸º $B_c = \min\left(\frac{M}{4d}, d\right)$ ã€‚ $\min$ å‡½æ•°çš„ç›®çš„æ˜¯é˜²æ­¢å—å¤§å° $B_r \times B_c > M/4$ï¼Œè¿™æ ·å°±æ— æ³•æŠŠ 4 ä¸ªè¿™æ ·çš„å—æ”¾åˆ° SRAM é‡Œï¼Œåé¢æˆ‘ä»¬ä¼šçœ‹åˆ°ä¸ºä»€ä¹ˆæ˜¯ $4 \times B_r \times B_c$ çš„å—ã€‚
![](Figure/flashattention/step1(1).png)
---
2. æˆ‘ä»¬æŠŠç»“æœçŸ©é˜µOåˆå§‹åŒ–ä¸ºé›¶ï¼Œåé¢ä¼šé€æ­¥æŠŠä¸­é—´ç»“æœç´¯åŠ è¿›å»ï¼Œæ‰€ä»¥é›¶æ˜¯åˆé€‚çš„åˆå§‹å€¼ã€‚ç±»ä¼¼çš„æ˜¯l(æ³¨æ„ï¼šå¯¹äºæ¯ä¸€è¡Œæ¥è¯´ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œç”¨äºç´¯åŠ æŒ‡æ•°å’Œï¼Œç”±äºè¾“å‡ºæœ‰Nè¡Œï¼Œæ‰€ä»¥è¿™é‡Œçš„læ˜¯é•¿åº¦ä¸ºNçš„å‘é‡)ã€‚mç”¨äºè®°å½•æ¯ä¸€è¡Œå½“å‰æœ€å¤§çš„å€¼ï¼Œæ‰€ä»¥ä¹Ÿæ˜¯é•¿åº¦ä¸ºNï¼Œè€Œ-infæ˜¯æ±‚maxçš„åˆé€‚åˆå§‹å€¼ã€‚
![](Figure/flashattention/step2.png)
---
3. è®¾ç½®å—çš„è¡Œå¤§å°$B_r = \frac{M}{4d}$ï¼Œå—çš„åˆ—å¤§å°ä¸º$B_c = \min\left(\frac{M}{4d}, d\right)$ã€‚$\min$å‡½æ•°çš„ç›®çš„æ˜¯é˜²æ­¢å—å¤§å°$B_r \times B_c > M/4$ï¼Œè¿™æ ·å°±æ— æ³•æŠŠ4ä¸ªè¿™æ ·çš„å—æ”¾åˆ°SRAMé‡Œï¼Œåé¢æˆ‘ä»¬ä¼šçœ‹åˆ°ä¸ºä»€ä¹ˆæ˜¯$4 \times B_r \times B_c$çš„å—ã€‚
![](Figure/flashattention/step3.png)
---
4. æ ¹æ®å‰é¢çš„è®¡ç®—ï¼Œç»“æœçŸ©é˜µ$O$éœ€è¦åˆ‡åˆ†æˆ$ğµğ‘ŸÃ—ğ‘‘$çš„å—æ¥å­˜æ”¾ä¸­é—´ç»“æœã€‚é•¿åº¦ä¸º$N$çš„$l$å’Œ$m$ä¹Ÿè¦åˆ‡åˆ†æˆ$ğµğ‘Ÿ$ä¸ªå…ƒç´ çš„å—ï¼Œç”¨äºå­˜æ”¾è¿™äº›è¡Œå½“å‰çš„æŒ‡æ•°ç´¯åŠ å€¼å’Œå½“å‰æœ€å¤§å€¼ã€‚
![](Figure/flashattention/step4.png)
![](Figure/flashattention/tiling1.png)
![](Figure/flashattention/tiling2.png)
---
ç®—æ³•å›¾
![](Figure/flashattention/FAV1_9.png)
- è¿™ä¸ªå›¾å±•ç¤ºäº†ç¬¬5æ­¥å¼€å§‹çš„ä¸¤å±‚å¾ªç¯ï¼Œ**é€»è¾‘å°±æ˜¯å¤–å±‚å¾ªç¯çš„ä¸‹æ ‡ $j$ å°±æ˜¯å¾ªç¯ $K^T$ å’Œ $V$ï¼Œè€Œå†…å­˜å¾ªç¯çš„ä¸‹æ ‡å°±æ˜¯å¾ªç¯ $Q$**ã€‚é¦–å…ˆå¤–å±‚å¾ªç¯å–å‡ºå¤§å°ä¸º $d \times B_c$ çš„ $ K_j^T$ å’Œå¤§å°ä¸º $B_c \times d$ çš„ $V_j$ï¼Œç„¶åå†…å±‚å¾ªç¯éå†æ•´ä¸ª $Q$ï¼Œæ¯”å¦‚å½“å‰æ˜¯ $i$ï¼Œä¹Ÿå°±æ˜¯å¤§å°ä¸º $B_r \times d $ çš„ $Q_i$ã€‚æˆ‘ä»¬å°±å¯ä»¥è®¡ç®— $O = softmax(Q_i K_j^T V_j)$ã€‚ä¸è¿‡è¦è®°ä½ï¼Œè¿™æ˜¯éƒ¨åˆ†çš„è®¡ç®—ç»“æœï¼Œæ‰€ä»¥æˆ‘ä»¬è¦ä¿å­˜ï¼ˆæ›´æ–°ï¼‰ä¸­é—´ç»Ÿè®¡é‡ $m$ å’Œ $l$ï¼Œç­‰åˆ° $j+1$ çš„ä¸‹ä¸€æ¬¡å¾ªç¯æ—¶ï¼Œå†…å±‚å¾ªç¯è¿˜ä¼šå†æ¬¡éå† $Q$ï¼Œé‚£ä¸ªæ—¶å€™ä¼šè®¡ç®— $O = softmax(Q_i K_{j+1}^T V_{j+1})$ï¼Œç„¶åæŠŠè¿™æ¬¡çš„ç»“æœåˆå¹¶åˆ°æœ€ç»ˆçš„ç»“æœé‡Œã€‚åŒ…æ‹¬ç»Ÿè®¡é‡ä¹Ÿéœ€è¦åŒæ­¥æ›´æ–°ã€‚
- **å†…å¾ªç¯ä¸€æ¬¡ $Q_i$ å¡«æ»¡ä¸€æ¬¡ $Oã€lã€m$ï¼Œå…±å¾ªç¯$T_r$æ¬¡**
- **å¤–å¾ªç¯ä¸€æ¬¡ $K_j^Tã€V_j$ æ›´æ–°ä¸€æ¬¡ $Oã€lã€m$ï¼Œå…±å¾ªç¯$T_c$æ¬¡**
- **æ•´ä½“å¾ªç¯ç»“æŸ$Oã€lã€m$ å°±æ˜¯æœ€ç»ˆç»“æœ**
---
5. è¿™æ˜¯å¤–å±‚å¾ªç¯ï¼Œjè¡¨ç¤ºKå’ŒVçš„ä¸‹æ ‡ã€‚
![](Figure/flashattention/step5.png)
---
6. æˆ‘ä»¬é¦–å…ˆæŠŠ$K_j$å’Œ$V_j$ä»HBMåŠ è½½åˆ°SRAMã€‚æ ¹æ®å‰é¢çš„è®¨è®ºï¼Œè¿™ä¼šå æ®SRAM **çº¦50%** çš„å­˜å‚¨ã€‚($B_c = \min\left(\frac{M}{4d}, d\right)$ï¼Œå¦‚æœ$B_r = \frac{M}{4d}$ï¼Œ$2 \times B_r \times d = \frac{M}{2}$ï¼Œæ­£å¥½å 50%çš„SRAM; å¦‚æœ$B_r = d$, åˆ™è¯´æ˜$d < \frac{M}{4d}$ï¼Œå SRAMä¼šå°äº50%)
![](Figure/flashattention/step6.png)
---
7. å†…å¾ªç¯ï¼Œiè¡¨ç¤ºQçš„ä¸‹æ ‡ã€‚
![](Figure/flashattention/step7.png)
---
8. æŠŠ$Q_i(B_r \times d)$å’Œ$O_i(B_r \times d)$åŠ è½½è¿›SRAMï¼ŒåŒæ—¶æŠŠ$l_i(B_r)$å’Œ$m_i(B_r)$ä¹ŸåŠ è½½è¿›å»ã€‚$Q_i$å’Œ$O_i$ä¼š**å æ®50%çš„æ˜¾å­˜**ã€‚è€Œ$l_i$å’Œ$m_i$æ¯”è¾ƒå°ï¼Œæ ¹æ®**è®ºæ–‡ä½œè€…çš„è¯´æ³•**å¯ä»¥æ”¾åˆ°å¯„å­˜å™¨é‡Œã€‚
![](Figure/flashattention/step8.png)
---
9. è®¡ç®—åˆ†å—çŸ©é˜µ$Q_i(B_r \times d)$å’Œ$K_j$çš„è½¬ç½®$(d \times B_c)$çš„ä¹˜ç§¯ï¼Œå¾—åˆ°score $S_{ij}(B_r \times B_c)$ã€‚
![](Figure/flashattention/step9.png)
æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¿™é‡Œä¸éœ€è¦è®¡ç®—$N \times N$çš„å¾—åˆ†SçŸ©é˜µï¼Œä¹Ÿå°±æ˜¯ä¸éœ€è¦â€œmaterializedâ€ã€‚è€Œåªéœ€è¦å¾ˆå°çš„$S_{ij}$ã€‚
æˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼šè¿™é‡Œå‡è®¾å¤–å±‚å¾ªç¯ä¸‹æ ‡$j=3$ï¼Œå†…å±‚å¾ªç¯ä¸‹æ ‡$i=2$ï¼Œ$N=25$ï¼Œå—å¤§å°æ˜¯5ï¼ˆè¿™é‡Œå‡è®¾ä¸‹æ ‡ä»1å¼€å§‹ï¼‰ã€‚é‚£ä¹ˆè®¡ç®—å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
$$
Q_i \cdot K_j^T = (B_r \times d) \cdot (d \times B_c) = B_r \times B_c
$$

![](Figure/flashattention/FAV1_10.png)
- ä¸Šå›¾è®¡ç®—çš„æ˜¯attentionå¾—åˆ†æ˜¯Queryä¸ºç¬¬6-10ä¸ªtokenï¼ŒKeyæ˜¯ç¬¬11-15ä¸ªtokenã€‚
---
10. è®¡ç®—$\tilde{m}_{ij}$ã€$\tilde{l}_{ij}$å’Œ$\tilde{P}_{ij}$ï¼Œä½¿ç”¨å‰é¢çš„å…¬å¼å°±å¯ä»¥ç®€å•çš„å¾—å‡ºã€‚
![](Figure/flashattention/step10.png)
- $\tilde{m}_{ij}$æ˜¯é€è¡Œè®¡ç®—çš„ï¼Œæ‰¾åˆ°æ¯ä¸€è¡Œçš„æœ€å¤§å€¼ã€‚
- $\tilde{P}_{ij}$æ˜¯é€ç‚¹è¿ç®—ï¼ŒæŠŠ$S_{ij}$å‡å»ç¬¬$i$è¡Œçš„æœ€å¤§å€¼$\tilde{m}_{ij}$ï¼ˆæ³¨æ„ï¼šè¿™ä¸ªä¸‹æ ‡$j$è¡¨ç¤ºè¿™æ˜¯ç¬¬$j$æ¬¡è®¡ç®—ï¼Œå…¶å®æ˜¯ä¸€ä¸ªå€¼è€Œä¸æ˜¯å‘é‡ï¼‰ï¼Œç„¶ååœ¨è®¡ç®—æŒ‡æ•°ã€‚
- $\tilde{l}_{ij}$ä¹Ÿæ˜¯é€è¡Œè®¡ç®—ï¼ŒæŠŠæ¯ä¸€è¡Œçš„$\tilde{P}_{ij}$åŠ èµ·æ¥ã€‚

---
11. 
- $m_i$åŒ…å«äº†åœ¨å½“å‰å—ï¼ˆ$j=3$ï¼‰ä¹‹å‰æ‰€æœ‰å—çš„æœ€å¤§å€¼ï¼ˆæŒ‰è¡Œï¼‰ï¼Œæ¯”å¦‚ä¸Šé¢çš„ä¾‹å­ï¼Œ$m_i$ä¿å­˜äº†$j=1$å’Œ$j=2$ï¼ˆå›¾ä¸­çš„ç»¿è‰²å—ï¼‰å—ç¬¬6~10è¡Œçš„æœ€å¤§å€¼ã€‚è€Œ$\tilde{m}_{ij}$æ˜¯ä¸Šä¸€æ­¥å¾—åˆ°çš„å½“å‰å—ï¼ˆé»„è‰²ï¼‰çš„æœ€å¤§å€¼ã€‚å› æ­¤å–å®ƒä»¬ä¸¤è€…çš„æœ€å¤§å€¼å°±å¾—åˆ°å‰3ä¸ªå—ï¼ˆç»¿è‰²åŠ é»„è‰²å—å…±15åˆ—ï¼‰çš„æœ€å¤§å€¼ã€‚
- $l_i^{new}$çš„è®¡ç®—ä¹Ÿæ˜¯ç±»ä¼¼çš„ï¼Œåªä¸è¿‡æ±‚å’Œå‰éœ€è¦ç”¨å½“å‰çš„$e^{-m_i^{new}}$ä¿®æ­£ï¼Œå…·ä½“å¯å‚è€ƒ[Naive -> Safe -> Online Softmax](https://summer536.github.io/Notes/zh/posts/softmax.html)ã€‚
![](Figure/flashattention/step11.png)
![](Figure/flashattention/FAV1_11.png)

---
12. è¿™é‡Œå…ˆä»‹ç»ä¸€ä¸‹$diag(l_i)$ï¼Œå®ƒæ˜¯ä¸€ä¸ªå¯¹è§’çŸ©é˜µï¼Œå¯¹è§’çº¿ä¸Šçš„å…ƒç´ æ˜¯$l_i$ã€‚(diag( )å°†ä¸€ä¸ª$N*1$çš„å‘é‡å˜æˆ$N*N$çš„å¯¹è§’çŸ©é˜µ, å¦‚ä¸‹å›¾å·¦ä¾§çŸ©é˜µ)ä¸ºä»€ä¹ˆè¦æå‡ºè¿™ä¹ˆå¤æ‚çš„ä¸œè¥¿å‘¢ï¼Ÿç›®çš„å°±æ˜¯æŠŠå‰é¢æˆ‘ä»¬æ›´æ–°lçš„å…¬å¼èƒ½å†™æˆçŸ©é˜µä¹˜æ³•çš„å½¢å¼ï¼Œè¿™æ ·æ‰èƒ½åœ¨GPUä¸Šé«˜æ•ˆè®¡ç®—ã€‚
![](Figure/flashattention/FAV1_12.png)
![](Figure/flashattention/FAV1_13.png)

![](Figure/flashattention/step12.png)
ç¬¬12æ­¥å…¬å¼çš„**ç»¿è‰²éƒ¨åˆ†æ˜¯æ›´æ–°å½“å‰å—ï¼ˆ$j=3$ï¼‰ä¹‹å‰çš„å—ï¼ˆ$j<3$ï¼‰çš„ softmax å€¼**ã€‚

æˆ‘ä»¬å›å¿†ä¸€ä¸‹å‰é¢çš„ä¾‹å­ï¼šåœ¨ä¸€å¼€å§‹ $x^1 = [x_1 = 1, x_2 = 3]$ï¼Œå‰ä¸¤ä¸ªæ•°çš„ softmax å€¼æ˜¯ï¼š

$$
l = e^{1-3} + e^{3-3}
$$

$$
PV = [e^{1-3}, e^{3-3}]
$$

$$
O = \left[ \frac{e^{1-3}}{e^{1-3} + e^{3-3}}, \frac{e^{3-3}}{e^{1-3} + e^{3-3}} \right]
$$

ç°åœ¨ $x^2 = [x_3 = 2, x_4 = 4]$ åŠ å…¥ï¼Œä½¿å¾—æœ€å¤§å€¼å˜æˆäº† 4ï¼Œå¹¶ä¸”æŒ‡æ•°çš„å’Œä¹Ÿå¢åŠ äº†ã€‚æ‰€ä»¥ç¬¬ä¸€æ­¥çš„éœ€è¦é‡æ–°è®¡ç®—ã€‚æ€ä¹ˆé‡æ–°è®¡ç®—å‘¢ï¼Ÿå› ä¸ºä¹‹å‰çš„ PV æ²¡æœ‰ä¿å­˜ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç”¨ $l$ ä¹˜ä»¥ $O$ æ¢å¤å‡º PVã€‚è®ºæ–‡ä¸­æ˜¯çŸ©é˜µçš„å½¢å¼ï¼Œä¹Ÿå°±æ˜¯ $diag(l_i) \times O_i$ã€‚æ¢å¤å‡ºæ¥çš„ R å†ä¹˜ä»¥ $e^{m_i - m_i^{new}}$ å°±æ˜¯ä¿®æ­£åçš„ PVï¼Œä¹Ÿå°±æ˜¯ $e^{x_i - max(x)} V_j$ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹äºä¸Šé¢çš„ä¾‹å­ï¼Œåšè¿™ä¸€æ­¥ä¹‹åPVå°†ä¼šè®¡ç®—ä¸º:
$$
PV =l\times O \times e^{m_i - m_i^{new}} =[e^{1-3}, e^{3-3}] \times e^{3-4} = [e^{1-4}, e^{3-4}]
$$

è€Œ**å…¬å¼çš„é»„è‰²éƒ¨åˆ†æ˜¯å½“å‰å—ï¼ˆ$j=3$ï¼‰ï¼Œ$e^{\tilde{m}_{ij} - m_i^{new}}$ æ˜¯å½“å‰å—çš„æœ€å¤§å€¼å‡å» $j \leq 3$ æ‰€æœ‰å—çš„æœ€å¤§å€¼ï¼Œè¿™æ˜¯å¯¹å½“å‰æŒ‡æ•° $\tilde{P}_{ij}$ çš„ä¿®æ­£**ã€‚ä»£å…¥$\tilde{P}_{ij} = e^{S_{ij} - \tilde{m}_{ij}}$ï¼ˆç¬¬åæ­¥ï¼‰ï¼Œé‚£ä¹ˆå¯ä»¥å‘ç°å…¶å®å°±æ˜¯ $e^{S_{ij} - m_i^{new}}$ã€‚é»„è‰²éƒ¨åˆ†ä¹˜$V_j$åˆ™å®Œæˆäº†å½“å‰å—çš„$O_i = softmax(Q_i K_j^T V_j)$é™¤æœ€åä¸€æ­¥softmaxè¦é™¤ä»¥$l$çš„æ‰€æœ‰æ­¥éª¤ã€‚

**æœ€åæŠŠæ–°çš„ PV é™¤ä»¥æ–°çš„ $l$ å­˜åˆ° $O$ é‡Œ(å®Œæ•´softmaxçš„æœ€åä¸€æ­¥)ï¼Œåªä¸è¿‡è¿™é‡Œçš„é™¤æ³•ä¹Ÿæ˜¯ç”¨çŸ©é˜µä¹˜æ³•æ¥è¡¨ç¤ºï¼Œä¹Ÿå°±æ˜¯æœ€å‰é¢çš„ $(diag(l_i^{new}))^{-1}$ã€‚å› ä¸ºå¯¹è§’çŸ©é˜µçš„é€†å°±æ˜¯å®ƒå¯¹è§’çº¿å…ƒç´ çš„é€†ï¼Œä¹Ÿå°±æ˜¯å˜æˆäº†é™¤æ³•ã€‚**

---
13. æŠŠæœ€æ–°çš„ç´¯è®¡é‡$l_r,m_r$å†™å›HBMï¼Œæ³¨æ„å®ƒä»¬çš„å¤§å°éƒ½æ˜¯$B_r$ã€‚
![](Figure/flashattention/step13.png)

---
14.-16. ç»“æŸå¾ªç¯ï¼Œè¿”å›æœ€ç»ˆçŸ©é˜µOã€‚

### 1.4 FAV1ç®—æ³•çš„æ•°å­¦è¯æ˜
#### 1.4.1 Online Softmax
è¿™ä¸ªè¯æ˜ç•¥ï¼Œè¯¦ç»†å†…å®¹è§ç¬”è®°[Naive -> Safe -> Online Softmax](https://summer536.github.io/Notes/zh/posts/softmax.html)

#### 1.4.2 å¦‚ä½•è¯æ˜æœ€ç»ˆè®¡ç®—çš„Oæ˜¯æ­£ç¡®çš„ï¼Ÿ
æˆ‘ä»¬ç”¨**æ•°å­¦å½’çº³æ³•**æ¥è¯æ˜ç®—æ³•çš„æ­£ç¡®æ€§ï¼Œè¿™é‡Œæˆ‘ä»¬ç”¨å¤–å¾ªç¯ä¸‹æ ‡ $0 \leqslant j \leqslant T_c$ æ¥è¿›è¡Œå½’çº³ã€‚

é¦–å…ˆæˆ‘ä»¬è®° $K_{:,j} \in R^{jB_c \times d}$ ä¸º K çš„å‰ $jB_c$ è¡Œï¼Œ$V_{:,j} \in R^{jB_c \times d}$ ä¸º V çš„å‰ $jB_c$ è¡Œã€‚

ä»¤ $S_{:,j} = QK^{T}_{:,j} \in R^{N \times jB_c}$ï¼Œ$P_{:,j} = \text{softmax}(S_{:,j}) \in R^{N \times jB_c}$ã€‚

$K_{:,j}$ æ˜¯ K çš„å‰ $jB_c$ è¡Œï¼Œæ‰€ä»¥ $K_{:,j}^T \in R^{d \times jB_c}$ æ˜¯ K çš„å‰ $jB_c$ åˆ—ï¼Œæ‰€ä»¥ $S_{:,j}$ æ˜¯çŸ©é˜µ Q ä¹˜ä»¥ K çš„å‰ $jB_c$ åˆ—ï¼ˆè¡Œæ˜¯ Nï¼‰ã€‚è€Œ $P_{:,j}$ æ˜¯å‰ $jB_c$ åˆ—çš„ softmaxï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬ä¹‹å‰ç®—æ³•å¤–å±‚å¾ªç¯ã€‚

![](Figure/flashattention/FAV1_14.png)

ä»¤ $m^{(j)}, l^{(j)}, O^{(j)}$ æ˜¯ç®—æ³•åœ¨ç¬¬ j æ¬¡å¤–å¾ªç¯ç»“æŸå HBM ä¿å­˜çš„ç´¯ç§¯é‡å’Œ $\text{softmax}(QK^TV)$ï¼ˆéƒ¨åˆ†æ­£ç¡®ï¼‰çš„ç»“æœã€‚**æ³¨æ„ï¼šå¯¹äºå›ºå®šçš„ iï¼Œè¿™äº›é‡åœ¨æ¯æ¬¡å¤–å¾ªç¯ j ç»“æŸåéƒ½ä¼šè¢«æ›´æ–°åˆ° HBM ä¸­ï¼Œä¸‹ä¸€æ¬¡å¤–å¾ªç¯æ—¶åˆåŠ è½½å›æ¥ã€‚** æˆ‘ä»¬æƒ³è¯æ˜ï¼šç¬¬ j æ¬¡å¤–å¾ªç¯ç»“æŸåï¼ŒHBM ä¸­çš„å€¼ä¸ºï¼š

$$
m^{(j)} = \text{rowmax}(S_{:,j}) \in R^N
$$

$$
l^{(j)} = \text{rowsum}(\exp(S_{:,j} - m^{(j)})) \in R^N
$$

$$
O^{(j)} = P_{:,j}V_{:,j} \in R^{N \times d}
$$

æ ¹æ®ç®—æ³•çš„åˆå§‹åŒ–ï¼ˆç¬¬ 1 å’Œ 2 è¡Œï¼‰ï¼Œ$j=0$ æ˜¯æ˜¾ç„¶æ˜¯æ­£ç¡®çš„ï¼Œå› ä¸ºç´¯ç§¯é‡ $m$ åˆå§‹åŒ–ä¸º $-\infty$ï¼Œ$l$ åˆå§‹åŒ–ä¸º 0ï¼Œ$O$ ä¹Ÿæ˜¯åˆå§‹åŒ–ä¸º 0ã€‚

---
å‡è®¾ $j$ æ—¶ç»“è®ºæ˜¯æ­£ç¡®çš„ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¸Œæœ›è¯æ˜ $j+1$ æ˜¯ä¸Šé¢ä¸‰ä¸ªå¼å­ä¹Ÿæ˜¯æ­£ç¡®çš„ã€‚

é¦–å…ˆæˆ‘ä»¬çœ‹ç´¯ç§¯é‡ $m$ï¼Œå®ƒçš„æ›´æ–°ç®—æ³•æ˜¯ï¼š$\tilde{m}^{(j+1)} = \max(m^{(j)}, \tilde{m})$ï¼Œå…¶ä¸­ $\tilde{m} \in R^N$ æ˜¯å— $j$ çš„æœ€å¤§å€¼ï¼ˆæŒ‰è¡Œï¼‰ï¼Œå› æ­¤å®ƒç­‰äº $\max(S_{:,j:j+1})$ã€‚æ ¹æ®å½’çº³ï¼Œè€Œ $m^{(j)} = \max(S_{:,j})$ï¼Œæ‰€ä»¥ï¼š

$$
m^{(j+1)} = \max(m^{(j)}, \tilde{m}) = \max(\max(S_{:,j:j+1}), \max(S_{:,j})) = \text{rowmax}(S_{:,j+1})
$$

è¿™å°±**è¯æ˜äº†å¯¹äº $j+1$ï¼Œç¬¬ä¸€ä¸ªç­‰å¼æ˜¯æˆç«‹çš„**ã€‚ç±»ä¼¼çš„ï¼Œæˆ‘ä»¬çš„æ›´æ–° $l$ çš„ç®—æ³•æ˜¯ï¼š

$$
l^{(j+1)} = \left(e^{m^{(j)} - m^{(j+1)}} l^{(j)} + e^{\tilde{m} - m^{(j+1)}} \tilde{l}\right)
$$

å…¶ä¸­ $\tilde{l} = \text{rowsum}(\exp(S_{:,j:j+1} - \tilde{m})) \in R^N$ã€‚å› æ­¤ï¼š

$$
l^{(j+1)} = e^{m^{(j)} - m^{(j+1)}} l^{(j)} + e^{\tilde{m} - m^{(j+1)}} \text{rowsum}(\exp(S_{:,j:j+1} - \tilde{m}))
$$

è€Œæ ¹æ®å½’çº³ï¼š

$$
l^{(j)} = \text{rowsum}(\exp(S_{:,j} - m^{(j)}))
$$

ä»£å…¥ä¸Šå¼å¾—åˆ°ï¼š

$$
\begin{aligned}
l^{(j+1)} &= e^{m^{(j)} - m^{(j+1)}} \text{rowsum}(\exp(S_{:,j} - m^{(j)})) + e^{\tilde{m} - m^{(j+1)}} \text{rowsum}(\exp(S_{:,j:j+1} - \tilde{m})) \\
&= \text{rowsum}(\exp(S_{:,j} - m^{(j+1)})) + \text{rowsum}(\exp(S_{:,j:j+1} - m^{(j+1)})) \\
&= \text{rowsum}(\exp(S_{:,j+1} - m^{(j+1)}))
\end{aligned}
$$

æ‰€ä»¥**åœ¨ $j+1$ æ—¶ç¬¬äºŒä¸ªå¼å­æˆç«‹**ã€‚

ä¸ºäº†è¯æ˜ç¬¬ä¸‰ä¸ªå¼å­ï¼Œæˆ‘ä»¬ä»¤ $V_{:,j:j+1}$ ä¸º V çš„ç¬¬ $jB_c$ åˆ—åˆ° $(j+1)B_c-1$ åˆ—ã€‚è¯æ˜è¿‡ç¨‹å¦‚ä¸‹ï¼š

$$
\begin{aligned}
\mathbf{O}^{(j+1)} &= \text{diag}(\ell^{(j+1)})^{-1} (\text{diag}(\ell^{(j)}) e^{m^{(j)} - m^{(j+1)}} \mathbf{O}^{(j)} + e^{\tilde{m} - m^{(j+1)}} \exp(\mathbf{S}_{:,j:j+1} - \tilde{m}) \mathbf{V}_{:,j:j+1}) \\
&= \text{diag}(\ell^{(j+1)})^{-1} (\text{diag}(\ell^{(j)}) e^{m^{(j)} - m^{(j+1)}} \mathbf{P}_{:,j} \mathbf{V}_{:,j} + e^{-m^{(j+1)}} \exp(\mathbf{S}_{:,j:j+1}) \mathbf{V}_{:,j:j+1}) \\
&= \text{diag}(\ell^{(j+1)})^{-1} (\text{diag}(\ell^{(j)}) e^{m^{(j)} - m^{(j+1)}} ({\text{diag}(\ell^{(j)})})^{-1} \exp(\mathbf{S}_{:,j} - m^{(j)}) \mathbf{V}_{:,j} + e^{-m^{(j+1)}} \exp(\mathbf{S}_{:,j:j+1}) \mathbf{V}_{:,j:j+1}) \\
&= \text{diag}(\ell^{(j+1)})^{-1} (e^{-m^{(j+1)}} \exp(\mathbf{S}_{:,j}) \mathbf{V}_{:,j} + e^{-m^{(j+1)}} \exp(\mathbf{S}_{:,j:j+1}) \mathbf{V}_{:,j:j+1}) \\
&= \text{diag}(\ell^{(j+1)})^{-1} (\exp(\mathbf{S}_{:,j} - m^{(j+1)}) \mathbf{V}_{:,j} + \exp(\mathbf{S}_{:,j:j+1} - m^{(j+1)}) \mathbf{V}_{:,j:j+1}) \\
&= \text{diag}(\ell^{(j+1)})^{-1} \left( \exp \left( \begin{bmatrix} \mathbf{S}_{:,j} & \mathbf{S}_{:,j:j+1} \end{bmatrix} - m^{(j+1)} \right) \right) \begin{bmatrix} \mathbf{V}_{:,j} \\ \mathbf{V}_{:,j:j+1} \end{bmatrix} \\
&= \text{softmax}(\mathbf{S}_{:,j+1}) \mathbf{V}_{:,j+1}.
\end{aligned}
$$

ä¸‹é¢æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥åœ°æ¥çœ‹è¿™ä¸ªè¯æ˜è¿‡ç¨‹ã€‚

1. **ç¬¬ä¸€è¡Œ** è¿™å°±æ˜¯ç®—æ³•çš„æ›´æ–°å…¬å¼ã€‚åœ¨å‰é¢çš„ step 12 è¯¦ç»†ä»‹ç»äº†ã€‚

2. **ç¬¬äºŒè¡Œ** ç¬¬ä¸€ä¸ªæ˜¯ç”¨å½’çº³å‡è®¾ $\mathbf{O}^{(j)} = P_{:,j} V_{:,j}$ï¼Œç¬¬äºŒä¸ªå°±æ˜¯æŒ‡æ•°åˆå¹¶ï¼Œ$e^{\tilde{m}}$ æŠµæ¶ˆæ‰ã€‚

3. **ç¬¬ä¸‰è¡Œ** åˆ©ç”¨å‰é¢çš„å®šä¹‰ï¼š$P_{:,j} = \text{softmax}(S_{:,j})$ï¼Œä¹Ÿå°±æ˜¯è¯´ $P_{:,j}$ åˆ°å— j æ—¶çš„ $S_{:,j}$ çš„ softmaxã€‚æ ¹æ® softmax å’Œ l åŠ m çš„å…³ç³»ï¼Œæˆ‘ä»¬æœ‰ï¼š

   $$
   S_{:,j} = e^{S_{:,j} - m^{(j)}} / \begin{pmatrix} l_1^{(j)} & \dots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \dots & l_N^{(j)} \end{pmatrix} = (\text{diag}(l^{(j)}))^{-1} e^{S_{:,j} - m^{(j)}}
   $$

   ä»£å…¥å³å¯å¾—åˆ°ç¬¬ä¸‰è¡Œã€‚
4) **ç¬¬å››è¡Œ** $(\text{diag}(l^{(j)}))^{-1}$ å’Œ $\text{diag}(l^{(j)})$ æŠµæ¶ˆï¼Œ$e^{m^{(j)}}$ å’Œ $\exp(-m^{(j)})$ æŠµæ¶ˆï¼Œå°±å¾—åˆ°ç¬¬å››è¡Œã€‚

5) **ç¬¬äº”è¡Œ** æŠŠ $e^{-m^{(j+1)}}$ åˆå¹¶åˆ° $\exp(\dots)$ é‡Œé¢å°±å¾—åˆ°ç¬¬äº”è¡Œã€‚

6) **ç¬¬å…­è¡Œ** æŠŠ $A \times B + C \times D$ å†™æˆ $[A, C] \times [B, D]^T$ çš„çŸ©é˜µä¹˜æ³•ï¼ˆå‘é‡å†…ç§¯ï¼‰ã€‚

7) **ç¬¬ä¸ƒè¡Œ** å°±æ˜¯ softmax çš„å®šä¹‰ã€‚æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦æŠŠ $[\mathbf{S}_{:,j}, \mathbf{S}_{:,j:j+1}]$ åˆå¹¶æˆ $[\mathbf{S}_{:,j+1}]$ï¼Œ$[\mathbf{V}_{:,j}, \mathbf{V}_{:,j:j+1}]$ åˆå¹¶æˆ $[\mathbf{V}_{:,j+1}]$ã€‚

æ‰€ä»¥å¯¹äº $j+1$ï¼Œæˆ‘ä»¬è¯æ˜çš„ 3 ä¸ªå…¬å¼éƒ½æ˜¯æˆç«‹çš„ï¼Œå› æ­¤ç”¨æ•°å­¦å½’çº³æ³•å¯ä»¥è¯æ˜å¯¹äº $j = 0, \dots, T_c$ éƒ½æ˜¯æˆç«‹çš„ã€‚

å½“ $j = T_c$ æ—¶ï¼Œæ ¹æ®ç¬¬ä¸ƒè¡Œå’Œ $\mathbf{S}$ çš„å®šä¹‰ï¼Œ$\mathbf{O}^{(T_c)} = \text{softmax}(\mathbf{S}_{:,T_c} \mathbf{V}_{:,T_c}) = \text{softmax}(QK^T)V$ã€‚

#### 1.4.3 å¦‚ä½•è¯æ˜è®¡ç®—FLOPSä¸º$O(N^2d)$?
ç®—æ³•æœ€ä¸»è¦çš„ FLOPs ç”¨äºçŸ©é˜µä¹˜æ³•ã€‚åœ¨å†…å±‚å¾ªç¯ï¼ˆç®—æ³•ç¬¬ 9 è¡Œï¼‰ï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®— $Q_i K_j^T \in R^{B_r \times B_c}$ï¼Œå…¶ä¸­ $Q_i \in R^{B_r \times d}$ï¼Œ$K_j^T \in R^{d \times B_c}$ï¼Œè¿™éœ€è¦ $O(B_r B_c d)$ çš„ FLOPsã€‚å†…å¤–å¾ªç¯ç›¸ä¹˜æ˜¯ $T_c T_r = \left\lceil \frac{N}{B_c} \right\rceil \left\lceil \frac{N}{B_r} \right\rceil$ æ¬¡ï¼Œå› æ­¤æ€»çš„ TLOPs ä¸ºï¼š

$$
O\left(\frac{N^2}{B_c B_r} B_r B_c d\right) = O(N^2 d)
$$

å…³äºé¢å¤–çš„ç©ºé—´ï¼Œæˆ‘ä»¬éœ€è¦O(N)çš„ç©ºé—´æ¥å­˜å‚¨ç´¯è®¡é‡(l,m)ã€‚


#### 1.4.4 å¦‚ä½•è¯æ˜ç®—æ³•åªéœ€è¦$Î˜(ğ‘^2 ğ‘‘^2 ğ‘€^{âˆ’1})$çš„HBMè®¿é—®ï¼Ÿ
è¯æ˜ï¼šæˆ‘ä»¬é¦–å…ˆåˆ†ææ ‡å‡† Attention å®ç°çš„ IO æƒ…å†µã€‚è¾“å…¥ $Q, K, V \in R^{N \times d}$ åœ¨ HBM ä¸­ï¼Œæœ€ç»ˆçš„è¾“å‡º $O \in R^{N \times d}$ ä¹Ÿè¦å†™å›åˆ° HBMã€‚

ç¬¬ä¸€æ­¥æ˜¯è®¡ç®— $QK^T$ï¼Œè¿™æ˜¯ $(N \times d)$ çŸ©é˜µä¹˜ä»¥ $d \times N$ çŸ©é˜µï¼Œè¾“å…¥ Q å’Œ K éœ€è¦è¯»å…¥ï¼Œç»“æœ $S \in R^{N \times N}$ éœ€è¦å†™å› HBMï¼Œå› æ­¤ HBM è®¿é—®é‡æ˜¯ $O(Nd + N^2)$ã€‚

ç¬¬äºŒæ­¥æ˜¯ $P = \text{softmax}(S)$ï¼Œè¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯ $N^2$ï¼Œå› æ­¤è®¿é—® HBM ä¸º $O(N^2)$ã€‚

æœ€åä¸€èˆ¬æ˜¯ $O = PV$ï¼ŒP å’Œ V éœ€è¦è¯»å…¥ SRAMï¼Œç»“æœå†™å› HBMï¼Œæ‰€ä»¥è®¿é—® HBM ä¸º $O(Nd + N^2)$ã€‚

ç»¼ä¸Šï¼Œ**æ ‡å‡† Attention ç®—æ³•éœ€è¦ $O(Nd + N^2)$ çš„ HBM è¯»å†™é‡**ã€‚

---

æ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹ FlashAttention ç®—æ³•ã€‚

å¤–å±‚å¾ªç¯åªéå†ä¸€æ¬¡ï¼Œå› æ­¤ K å’Œ V åªä» HBM åŠ è½½åˆ° SRAM ä¸€æ¬¡ï¼ŒQ å’Œ O éœ€è¦éå† $T_c$ æ¬¡ï¼Œæ¯æ¬¡éƒ½å®Œæ•´çš„æŠŠå®ƒä»¬åŠ è½½ä¸€éã€‚å› æ­¤ HBM çš„è®¿é—®é‡æ˜¯ $O(Nd + NdT_c) = O(NdT_c)$ã€‚

ä¸‹é¢æ¥çœ‹ $B_c$ å’Œ $B_r$ çš„çº¦æŸæ¡ä»¶ã€‚æˆ‘ä»¬éœ€è¦å¤§å°ä¸º $B_c \times d$ å— $K_j, V_j$ èƒ½å¤Ÿæ”¾åˆ° SRAM é‡Œï¼Œå› æ­¤ï¼š

$$
B_c \times d = O(M) \Leftrightarrow B_c = O\left(\frac{M}{d}\right)
$$

ç±»ä¼¼çš„ï¼Œå¤§å°ä¸º $B_r \times d$ çš„å— $Q_i$ å’Œ $O_i$ ä¹Ÿéœ€è¦èƒ½æ”¾è¿›å»ï¼Œå› æ­¤ï¼š

$$
B_r \times d = O(M) \Leftrightarrow B_r = O\left(\frac{M}{d}\right)
$$

æœ€åï¼Œæˆ‘ä»¬éœ€è¦ $S_{ij} \in R^{B_r \times B_c}$ ä¹Ÿèƒ½æ”¾è¿›å»ï¼Œå› æ­¤ï¼š

$$
B_r B_c = O(M)
$$

å› æ­¤ï¼Œæˆ‘ä»¬è¿™æ ·è®¾ç½®ï¼š

$$
B_c = O\left(\frac{M}{d}\right), \quad B_r = O\left(\min\left(\frac{M}{d}, \frac{M}{B_c}\right)\right) = O\left(\min\left(\frac{M}{d}, d\right)\right)
$$

å› æ­¤æœ‰ï¼š

$$
T_c = \frac{N}{B_c} = O\left(\frac{Nd}{M}\right)
$$

æ‰€ä»¥æœ‰ $O(NdT_c) = O(N^2d^2M^{-1})$ã€‚è¯æ¯•ã€‚

## äºŒã€Flashattention-V2

## ä¸‰ã€Flashattention-V3

## æ€»ç»“

## å¾…æ›´æ–°

## å‚è€ƒæ–‡çŒ®

1. [Dao, T., et al. (2022). FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.](https://proceedings.neurips.cc/paper_files/paper/2022/file/67d57c32e20fd0a7a302cb81d36e40d5-Paper-Conference.pdf)
2. [Dao, T., et al. (2023). FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning. ](https://arxiv.org/pdf/2307.08691)
3. [Flash Attention V1è®ºæ–‡è§£è¯»-æç†](https://fancyerii.github.io/2023/10/23/flashattention/)
4. [Flash Attention V1è®ºæ–‡è§£è¯»-Zhang](https://www.armcvai.cn/2024-10-02/flashattention1-paper.html)
5. [Flash Attention V2è®ºæ–‡è§£è¯»-Zhang](https://www.armcvai.cn/2024-10-05/flashattention2-paper.html)
6. [Flash Attention V3è®ºæ–‡è§£è¯»-Zhang](https://www.armcvai.cn/2024-10-06/flashattention3-paper.html)
7. [flashattention1-2-3 ç³»åˆ—æ€»ç»“-Zhang](https://www.armcvai.cn/2024-10-07/flashattention1-2-3-summary.html)
8. [Flash Attention1-çœŸæ­£æ„ä¹‰ä¸Šçš„scale dot product attentionçš„ç®—å­èåˆ-AIä¸æ­¢ç®—æ³•](https://mp.weixin.qq.com/s?__biz=Mzg2ODk4MzE2MQ==&mid=2247483875&idx=1&sn=a23ef737b03e5bdec1892a8818de0704&chksm=cea549f5f9d2c0e3832f10031de98dd4a243fd2411ffdacb434cc64a473452a148fc149ded47&scene=21#wechat_redirect)
9. [FlashAttentionV1V2ç®—æ³•è§£é‡Š-AIä¸æ­¢ç®—æ³•Bilibili](https://www.bilibili.com/video/BV1gzBqY4Evw?spm_id_from=333.788.videopod.sections&vd_source=f058beebb64c488b55915da416ee6086)