"use strict";(self.webpackChunkvuepress=self.webpackChunkvuepress||[]).push([[2386],{1721:(e,l,t)=>{t.r(l),t.d(l,{comp:()=>n,data:()=>r});var i=t(641);const a={},n=(0,t(6262).A)(a,[["render",function(e,l){return(0,i.uX)(),(0,i.CE)("div",null,l[0]||(l[0]=[(0,i.Fv)('<h1 id="cuda技术栈知识点" tabindex="-1"><a class="header-anchor" href="#cuda技术栈知识点"><span>CUDA技术栈知识点</span></a></h1><h2 id="cuda基础" tabindex="-1"><a class="header-anchor" href="#cuda基础"><span>CUDA基础</span></a></h2><ul class="task-list-container"><li><p>CUDA核心知识</p><ul><li>必须要会写CUDA，面试的时候手撕一定会存在</li><li>算子的手撕代码通常有： <ul class="task-list-container"><li>reduce <ul><li><a href="https://zhuanlan.zhihu.com/p/426978026" target="_blank" rel="noopener noreferrer">深入浅出GPU优化系列：reduce优化</a></li><li><a href="https://github.com/Liu-xiandong/How_to_optimize_in_GPU/blob/master/README.md" target="_blank" rel="noopener noreferrer">Github代码</a></li><li><a href="https://github.com/xlite-dev/LeetCUDA/tree/main/kernels/reduce" target="_blank" rel="noopener noreferrer">LeetCUDA</a></li></ul></li><li>矩阵乘（八股+可能手撕） <ul><li><a href="https://zhuanlan.zhihu.com/p/435908830" target="_blank" rel="noopener noreferrer">深入浅出GPU优化系列：GEMM优化（一）</a></li><li><a href="https://zhuanlan.zhihu.com/p/442930482" target="_blank" rel="noopener noreferrer">深入浅出GPU优化系列：GEMM优化（二）</a></li><li><a href="https://zhuanlan.zhihu.com/p/410278370" target="_blank" rel="noopener noreferrer">CUDA乘终极优化指南</a></li><li><a href="https://zhuanlan.zhihu.com/p/518857175" target="_blank" rel="noopener noreferrer">CUDA SGEMM矩阵乘法优化笔记—从入门到cublas</a></li><li><a href="https://github.com/xlite-dev/LeetCUDA/tree/main/kernels/hgemm" target="_blank" rel="noopener noreferrer">LeetCUDA</a></li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" id="task-item-0" checked="checked" disabled="disabled"><label class="task-list-item-label" for="task-item-0"> softmax</label><ul><li><a href="https://zhuanlan.zhihu.com/p/1892986988065453222" target="_blank" rel="noopener noreferrer">从naive到safe再到oneline softmax</a></li><li><a href="https://github.com/xlite-dev/LeetCUDA/tree/main/kernels/softmax" target="_blank" rel="noopener noreferrer">LeetCUDA</a></li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" id="task-item-1" checked="checked" disabled="disabled"><label class="task-list-item-label" for="task-item-1"> RMSNorm</label><ul><li><a href="https://github.com/xlite-dev/LeetCUDA/tree/main/kernels/rms-norm" target="_blank" rel="noopener noreferrer">LeetCUDA</a></li></ul></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" id="task-item-2" checked="checked" disabled="disabled"><label class="task-list-item-label" for="task-item-2"> layernorm</label></li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" id="task-item-3" checked="checked" disabled="disabled"><label class="task-list-item-label" for="task-item-3"> transpose</label></li></ul></li><li><strong>前两个算子</strong>要熟练掌握</li></ul></li><li><p>面试经典问题</p><ul><li>如何解决bank conflict？</li><li>写算子的时候如何进行roofline分析？</li><li>compute bound还是memory bound的判断？</li><li>算子的fusion策略？</li><li>tiling策略的优化？</li></ul></li><li class="task-list-item"><p><input type="checkbox" class="task-list-item-checkbox" id="task-item-4" checked="checked" disabled="disabled"><label class="task-list-item-label" for="task-item-4"> Flash Attention深入理解</label></p><ul><li>目前有V1、V2、V3三个版本</li><li>一般考察八股文，某些组会要求手撕v1和v2（v3因复杂度高不太可能）</li><li>推荐熊猫视频的讲解资料</li><li>从naive softmax到safe max，再到online softmax，最后到flash attention的发展路径</li></ul></li><li><p>编译链路</p><ul><li>CUDA到PTX到SASS这条链路至少得了解基本原理</li></ul></li></ul><h2 id="cutlass框架" tabindex="-1"><a class="header-anchor" href="#cutlass框架"><span>Cutlass框架</span></a></h2><ul><li>Cutlass（考察难度较高） <ul><li>每一代芯片的tensorcore实现</li><li>cute、swizzle、ldmatrix的用法</li><li>单精度、半精度矩阵乘的优化技术</li><li>hopper架构的TMA、Wgmma以及fp8的用法</li></ul></li></ul><h2 id="nvidia基础库" tabindex="-1"><a class="header-anchor" href="#nvidia基础库"><span>NVIDIA基础库</span></a></h2><ul><li>cuBLAS和cuDNN <ul><li>这些库的基本用法和接口</li><li>常用函数和性能优化方法</li></ul></li></ul><h2 id="性能分析工具" tabindex="-1"><a class="header-anchor" href="#性能分析工具"><span>性能分析工具</span></a></h2><ul><li>Profiler工具掌握 <ul><li>Nsight System（Nsys profile）：系统级性能分析</li><li>Nsight Compute（ncu）：内核级性能分析</li><li>如何分析和解读性能报告</li></ul></li></ul><h2 id="nvidia芯片架构" tabindex="-1"><a class="header-anchor" href="#nvidia芯片架构"><span>NVIDIA芯片架构</span></a></h2><ul><li>NV芯片架构的发展史 <ul><li>为什么TensorCore会发展到现在的形态？ <ul><li><a href="https://github.com/chenzomi12/AISystem/tree/main/02Hardware/04NVIDIA" target="_blank" rel="noopener noreferrer">Tensorcore介绍</a></li></ul></li><li>从Volta到Turing到Ampere再到Hopper再到Blackwall的演进 <ul><li><a href="https://www.bilibili.com/video/BV1mm4y1C7fg?spm_id_from=333.788.videopod.sections&amp;vd_source=f058beebb64c488b55915da416ee6086" target="_blank" rel="noopener noreferrer">Zomi视频</a></li></ul></li><li>两大发展方向： <ol><li>计算算力提升</li><li>访存的加速</li></ol></li><li>Hopper架构上加入TMA（张量内存访存单元）加速tensorcore的访存</li></ul></li></ul><h2 id="内存访问层级" tabindex="-1"><a class="header-anchor" href="#内存访问层级"><span>内存访问层级</span></a></h2><ul><li>内存访存层级理解 <ul><li>Host memory到HBM到L2到L1到寄存器等访存流程</li><li>各级缓存的特点和应用</li><li>数据搬运优化技术</li></ul></li></ul><h2 id="学习资源" tabindex="-1"><a class="header-anchor" href="#学习资源"><span>学习资源</span></a></h2><ul><li>重点学习谷歌HPC书签下的GitHub仓库</li><li>NVIDIA开发者文档</li><li>Cutlass官方文档和示例</li></ul>',15)]))}]]),r=JSON.parse('{"path":"/zh/posts/cuda-tech-stack.html","title":"CUDA技术栈","lang":"zh-CN","frontmatter":{"title":"CUDA技术栈","date":"2025-05-08T00:00:00.000Z","readingTime":60,"category":["CUDA","笔记"],"tag":["技术","GPU编程"],"description":"CUDA技术栈知识点 CUDA基础 CUDA核心知识 必须要会写CUDA，面试的时候手撕一定会存在 算子的手撕代码通常有： reduce 深入浅出GPU优化系列：reduce优化 Github代码 LeetCUDA 矩阵乘（八股+可能手撕） 深入浅出GPU优化系列：GEMM优化（一） 深入浅出GPU优化系列：GEMM优化（二） CUDA乘终极优化指南 ...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"CUDA技术栈\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-05-08T00:00:00.000Z\\",\\"dateModified\\":\\"2025-05-20T05:45:58.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"GYQ\\",\\"url\\":\\"https://github.com/Summer536\\"}]}"],["meta",{"property":"og:url","content":"https://your-domain.com/Notes/zh/posts/cuda-tech-stack.html"}],["meta",{"property":"og:site_name","content":"GYQ的博客"}],["meta",{"property":"og:title","content":"CUDA技术栈"}],["meta",{"property":"og:description","content":"CUDA技术栈知识点 CUDA基础 CUDA核心知识 必须要会写CUDA，面试的时候手撕一定会存在 算子的手撕代码通常有： reduce 深入浅出GPU优化系列：reduce优化 Github代码 LeetCUDA 矩阵乘（八股+可能手撕） 深入浅出GPU优化系列：GEMM优化（一） 深入浅出GPU优化系列：GEMM优化（二） CUDA乘终极优化指南 ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-05-20T05:45:58.000Z"}],["meta",{"property":"article:tag","content":"GPU编程"}],["meta",{"property":"article:tag","content":"技术"}],["meta",{"property":"article:published_time","content":"2025-05-08T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-05-20T05:45:58.000Z"}]]},"git":{"createdTime":1747123438000,"updatedTime":1747719958000,"contributors":[{"name":"yqgao","username":"yqgao","email":"gaoyuqing536@gmail.com","commits":4,"url":"https://github.com/yqgao"}]},"readingTime":{"minutes":2.13,"words":640},"filePathRelative":"zh/posts/cuda-tech-stack.md","excerpt":"\\n<h2>CUDA基础</h2>\\n<ul class=\\"task-list-container\\">\\n<li>\\n<p>CUDA核心知识</p>\\n<ul>\\n<li>必须要会写CUDA，面试的时候手撕一定会存在</li>\\n<li>算子的手撕代码通常有：\\n<ul class=\\"task-list-container\\">\\n<li>reduce\\n<ul>\\n<li><a href=\\"https://zhuanlan.zhihu.com/p/426978026\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">深入浅出GPU优化系列：reduce优化</a></li>\\n<li><a href=\\"https://github.com/Liu-xiandong/How_to_optimize_in_GPU/blob/master/README.md\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">Github代码</a></li>\\n<li><a href=\\"https://github.com/xlite-dev/LeetCUDA/tree/main/kernels/reduce\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">LeetCUDA</a></li>\\n</ul>\\n</li>\\n<li>矩阵乘（八股+可能手撕）\\n<ul>\\n<li><a href=\\"https://zhuanlan.zhihu.com/p/435908830\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">深入浅出GPU优化系列：GEMM优化（一）</a></li>\\n<li><a href=\\"https://zhuanlan.zhihu.com/p/442930482\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">深入浅出GPU优化系列：GEMM优化（二）</a></li>\\n<li><a href=\\"https://zhuanlan.zhihu.com/p/410278370\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">CUDA乘终极优化指南</a></li>\\n<li><a href=\\"https://zhuanlan.zhihu.com/p/518857175\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">CUDA SGEMM矩阵乘法优化笔记—从入门到cublas</a></li>\\n<li><a href=\\"https://github.com/xlite-dev/LeetCUDA/tree/main/kernels/hgemm\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">LeetCUDA</a></li>\\n</ul>\\n</li>\\n<li class=\\"task-list-item\\"><input type=\\"checkbox\\" class=\\"task-list-item-checkbox\\" id=\\"task-item-0\\" checked=\\"checked\\" disabled=\\"disabled\\"><label class=\\"task-list-item-label\\" for=\\"task-item-0\\"> softmax</label>\\n<ul>\\n<li><a href=\\"https://zhuanlan.zhihu.com/p/1892986988065453222\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">从naive到safe再到oneline softmax</a></li>\\n<li><a href=\\"https://github.com/xlite-dev/LeetCUDA/tree/main/kernels/softmax\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">LeetCUDA</a></li>\\n</ul>\\n</li>\\n<li class=\\"task-list-item\\"><input type=\\"checkbox\\" class=\\"task-list-item-checkbox\\" id=\\"task-item-1\\" checked=\\"checked\\" disabled=\\"disabled\\"><label class=\\"task-list-item-label\\" for=\\"task-item-1\\"> RMSNorm</label>\\n<ul>\\n<li><a href=\\"https://github.com/xlite-dev/LeetCUDA/tree/main/kernels/rms-norm\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">LeetCUDA</a></li>\\n</ul>\\n</li>\\n<li class=\\"task-list-item\\"><input type=\\"checkbox\\" class=\\"task-list-item-checkbox\\" id=\\"task-item-2\\" checked=\\"checked\\" disabled=\\"disabled\\"><label class=\\"task-list-item-label\\" for=\\"task-item-2\\"> layernorm</label></li>\\n<li class=\\"task-list-item\\"><input type=\\"checkbox\\" class=\\"task-list-item-checkbox\\" id=\\"task-item-3\\" checked=\\"checked\\" disabled=\\"disabled\\"><label class=\\"task-list-item-label\\" for=\\"task-item-3\\"> transpose</label></li>\\n</ul>\\n</li>\\n<li><strong>前两个算子</strong>要熟练掌握</li>\\n</ul>\\n</li>\\n<li>\\n<p>面试经典问题</p>\\n<ul>\\n<li>如何解决bank conflict？</li>\\n<li>写算子的时候如何进行roofline分析？</li>\\n<li>compute bound还是memory bound的判断？</li>\\n<li>算子的fusion策略？</li>\\n<li>tiling策略的优化？</li>\\n</ul>\\n</li>\\n<li class=\\"task-list-item\\">\\n<p><input type=\\"checkbox\\" class=\\"task-list-item-checkbox\\" id=\\"task-item-4\\" checked=\\"checked\\" disabled=\\"disabled\\"><label class=\\"task-list-item-label\\" for=\\"task-item-4\\"> Flash Attention深入理解</label></p>\\n<ul>\\n<li>目前有V1、V2、V3三个版本</li>\\n<li>一般考察八股文，某些组会要求手撕v1和v2（v3因复杂度高不太可能）</li>\\n<li>推荐熊猫视频的讲解资料</li>\\n<li>从naive softmax到safe max，再到online softmax，最后到flash attention的发展路径</li>\\n</ul>\\n</li>\\n<li>\\n<p>编译链路</p>\\n<ul>\\n<li>CUDA到PTX到SASS这条链路至少得了解基本原理</li>\\n</ul>\\n</li>\\n</ul>","autoDesc":true}')},6262:(e,l)=>{l.A=(e,l)=>{const t=e.__vccOpts||e;for(const[e,i]of l)t[e]=i;return t}}}]);