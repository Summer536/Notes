"use strict";(self.webpackChunkvuepress=self.webpackChunkvuepress||[]).push([[3524],{1709:(e,t,n)=>{n.d(t,{l:()=>i});const i=JSON.parse('{"category":{"/":{"path":"/category/","map":{"Guide":{"path":"/category/guide/","indexes":[0,1,2,3,4,5]},"笔记":{"path":"/category/%E7%AC%94%E8%AE%B0/","indexes":[6,7,8,9,10,11]},"CUDA":{"path":"/category/cuda/","indexes":[10,11]},"机器学习":{"path":"/category/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/","indexes":[8,9]},"深度学习":{"path":"/category/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/","indexes":[8,9]},"项目":{"path":"/category/%E9%A1%B9%E7%9B%AE/","indexes":[12,13]}}},"/en/":{"path":"/en/category/","map":{"Notes":{"path":"/en/category/notes/","indexes":[14,15,16]},"CUDA":{"path":"/en/category/cuda/","indexes":[16]},"Machine Learning":{"path":"/en/category/machine-learning/","indexes":[15]},"Deep Learning":{"path":"/en/category/deep-learning/","indexes":[15]},"Project":{"path":"/en/category/project/","indexes":[17]}}}},"tag":{"/":{"path":"/tag/","map":{"disable":{"path":"/tag/disable/","indexes":[2]},"encryption":{"path":"/tag/encryption/","indexes":[3]},"Layout":{"path":"/tag/layout/","indexes":[4]},"Markdown":{"path":"/tag/markdown/","indexes":[5]},"Page config":{"path":"/tag/page-config/","indexes":[0]},"Guide":{"path":"/tag/guide/","indexes":[0]},"技术":{"path":"/tag/%E6%8A%80%E6%9C%AF/","indexes":[10,11]},"GPU编程":{"path":"/tag/gpu%E7%BC%96%E7%A8%8B/","indexes":[10,11]},"注意力机制":{"path":"/tag/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/","indexes":[8,9]},"GPU优化":{"path":"/tag/gpu%E4%BC%98%E5%8C%96/","indexes":[8,9]},"大模型":{"path":"/tag/%E5%A4%A7%E6%A8%A1%E5%9E%8B/","indexes":[8,9]},"算法优化":{"path":"/tag/%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96/","indexes":[8,9]}}},"/en/":{"path":"/en/tag/","map":{"Technology":{"path":"/en/tag/technology/","indexes":[16]},"GPU Programming":{"path":"/en/tag/gpu-programming/","indexes":[16]},"Attention Mechanism":{"path":"/en/tag/attention-mechanism/","indexes":[15]},"GPU Optimization":{"path":"/en/tag/gpu-optimization/","indexes":[15]},"Large Models":{"path":"/en/tag/large-models/","indexes":[15]},"Algorithm Optimization":{"path":"/en/tag/algorithm-optimization/","indexes":[15]}}}}}')},2878:(e,t,n)=>{n.d(t,{P:()=>i});const i={GitHub:'<svg xmlns="http://www.w3.org/2000/svg" class="vp-social-media-icon github-icon" viewBox="0 0 1024 1024"><circle cx="512" cy="512" r="512" fill="#171515"/><path fill="#fff" d="M509.423 146.442c-200.317 0-362.756 162.42-362.756 362.8 0 160.266 103.936 296.24 248.109 344.217 18.139 3.327 24.76-7.872 24.76-17.486 0-8.613-.313-31.427-.49-61.702-100.912 21.923-122.205-48.63-122.205-48.63-16.495-41.91-40.28-53.067-40.28-53.067-32.937-22.51 2.492-22.053 2.492-22.053 36.407 2.566 55.568 37.386 55.568 37.386 32.362 55.438 84.907 39.43 105.58 30.143 3.296-23.444 12.667-39.43 23.032-48.498-80.557-9.156-165.246-40.28-165.246-179.297 0-39.604 14.135-71.988 37.342-97.348-3.731-9.178-16.18-46.063 3.556-96.009 0 0 30.46-9.754 99.76 37.19 28.937-8.048 59.97-12.071 90.823-12.211 30.807.14 61.843 4.165 90.822 12.21 69.26-46.944 99.663-37.189 99.663-37.189 19.792 49.946 7.34 86.831 3.61 96.01 23.25 25.359 37.29 57.742 37.29 97.347 0 139.366-84.82 170.033-165.637 179.013 13.026 11.2 24.628 33.342 24.628 67.182 0 48.498-.445 87.627-.445 99.521 0 9.702 6.535 20.988 24.945 17.444 144.03-48.067 247.881-183.95 247.881-344.175 0-200.378-162.442-362.798-362.802-362.798z"/></svg>',Email:'<svg xmlns="http://www.w3.org/2000/svg" class="vp-social-media-icon email-icon" viewBox="0 0 1024 1024"><circle cx="512" cy="512" r="512" fill="#1384FF"/><path fill="#fff" d="M270.077 286.233H751.99c32.933 0 59.86 24.855 60.274 55.51l-301.023 157L210.217 341.88c.207-30.723 26.927-55.717 59.86-55.717zm-59.929 115.714-.276 277.756c0 30.931 27.134 56.2 60.205 56.2H751.99c33.14 0 60.274-25.269 60.274-56.2V401.81L518.283 551.492a15.88 15.88 0 0 1-14.43 0L210.148 401.947z"/></svg>',BiliBili:'<svg xmlns="http://www.w3.org/2000/svg" class="vp-social-media-icon bilibili-icon" viewBox="0 0 1024 1024"><circle cx="512" cy="512" r="512" fill="#1296db"/><path fill="#fff" d="M745.363 177.725a47 47 0 0 1 0 66.3L702.5 286.85h44A141 141 0 0 1 887 427.512v281.25a141 141 0 0 1-141 140.626H277.25A141 141 0 0 1 137 708.763v-281.25a141 141 0 0 1 141-141h43.725l-42.788-42.825a47 47 0 1 1 66.263-66.3l99.45 99.45c2.963 2.962 5.438 6.187 7.425 9.637h120.487c1.988-3.45 4.5-6.75 7.463-9.675l99.413-99.45a47 47 0 0 1 66.3 0zm1.012 203.25h-468.75a47 47 0 0 0-46.763 43.388l-.112 3.525v281.25c0 24.712 19.125 44.962 43.387 46.724l3.488.15h468.75a47 47 0 0 0 46.763-43.387l.112-3.487v-281.25c0-26-21-47-47-46.876zm-375 93.75c26 0 47 21 47 47v47a47 47 0 1 1-93.75 0V521.6c0-26 21-47 47-47zm281.25 0c26 0 47 21 47 47v47a47 47 0 1 1-93.75 0V521.6c0-26 21-47 47-47z"/></svg>',Zhihu:'<svg xmlns="http://www.w3.org/2000/svg" class="vp-social-media-icon zhihu-icon" viewBox="0 0 1024 1024"><circle cx="512" cy="512" r="512" fill="#006CE2"/><path fill="#fff" d="M513.65 491.261H411.551c1.615-16.154 5.815-60.095 5.815-84.973 0-24.88-.323-60.742-.323-60.742h102.744V329.39c0-21.647-9.37-31.34-17.124-31.34h-178.67s5.169-17.77 10.015-36.186c4.846-18.417 15.832-44.264 15.832-44.264-63.003 4.2-67.958 50.941-81.743 92.729-13.787 41.785-24.556 62.356-44.586 107.912 27.786 0 55.249-13.57 66.879-32.309 11.631-18.74 16.908-40.71 16.908-40.71h62.035v59.019c0 21.107-3.878 87.45-3.878 87.45H254.742c-19.386 0-29.724 48.894-29.724 48.894h133.76c-8.4 75.82-26.493 106.191-51.91 152.716-25.418 46.525-92.728 99.406-92.728 99.406 41.033 11.63 86.589-3.555 105.974-21.972 19.386-18.417 35.863-49.756 47.817-72.838 11.954-23.081 21.972-65.124 21.972-65.124L498.462 766.86s4.846-24.233 6.461-39.418c1.616-15.186-.755-26.385-4.63-35.433-3.878-9.046-15.509-21.54-31.018-39.634-15.507-18.094-48.034-52.879-48.034-52.879s-15.832 11.63-28.108 21.001c9.046-21.97 16.262-79.695 16.262-79.695h122.343v-20.249c.003-17.66-7.319-29.29-18.089-29.29zm287.337-200.747h-234.35a4.308 4.308 0 0 0-4.309 4.308v435.099a4.308 4.308 0 0 0 4.308 4.308h40.226l14.7 50.402 81.096-50.402h98.328a4.308 4.308 0 0 0 4.308-4.308v-435.1a4.308 4.308 0 0 0-4.308-4.308zM755.97 684.47h-52.343l-61.548 39.095-10.823-39.095h-18.738V338.116H755.97v346.355z"/></svg>'}},3429:(e,t,n)=>{n.d(t,{B:()=>q});var i={};n.r(i),n.d(i,{default:()=>u});var a={};n.r(a);var o={};n.r(o);var r={};n.r(r);var l={};n.r(l),n.d(l,{default:()=>f});var s={};n.r(s),n.d(s,{default:()=>C});var c={};n.r(c);var d={};n.r(d);var h={};n.r(h),n.d(h,{default:()=>B});var p={};n.r(p),n.d(p,{default:()=>j});var m={};n.r(m),n.d(m,{default:()=>_});var g=n(5579);const u={enhance:({app:e})=>{e.component("GitContributors",g.B)}};var y=n(3349),b=n(1781),x=n(9212);const f={enhance:({app:e})=>{e.component("CodeTabs",b.S),e.component("Tabs",x.t)}};var A=n(2996),v=n(3027);const C={enhance:({app:e})=>{e.component("CodeDemo",A.A),e.component("MdDemo",v.A)}};var E=n(2417),P=n(355),k=n(457),U=n(4764),w=n(7786),T=n(641),D=n(307);const B={enhance:({app:e})=>{(0,U.L)("VPIcon")||e.component("VPIcon",(e=>(0,T.h)(D.G,{type:"iconify",prefix:"fa6-solid:",...e})))},setup:()=>{(0,w.r9V)("https://cdn.jsdelivr.net/npm/iconify-icon@2")}};var z=n(840),L=n(596),G=n(8831);n(2771);const j={enhance:({app:e})=>{(0,U.L)("Badge")||e.component("Badge",L.A),(0,U.L)("VPCard")||e.component("VPCard",G.A)},setup:()=>{},rootComponents:[]};var F=n(6358),M=n(3827),N=n(1599),I=n(4546),O=n(7923),S=n(4926),H=n(3175),V=n(8465),J=n(423),Y=n(1109),$=(n(2461),n(2472));n(7374),n(6829),n(6828),n(3248),(0,V.M_)((e=>{const t=e.title,n=e.index??!0,i=e.icon;return n?{title:t,content:i?()=>[(0,T.h)((0,T.g2)("VPIcon"),{icon:i,sizing:"both"}),t]:null,order:e.order,index:e.index}:null}));const _={enhance:({app:e,router:t})=>{const{scrollBehavior:n}=t.options;t.options.scrollBehavior=async(...e)=>(await O.s.wait(),n(...e)),(0,S.i)(e),e.component("BloggerInfo",J.m),e.component("SocialMedias",J.T),e.component("GlobalEncrypt",$.J),e.component("LocalEncrypt",$.n)},setup:()=>{(0,S.s)(),(0,S.a)(),(0,Y.su)()},layouts:{Layout:H.L,NotFound:H.N,Blog:J.B}},q=[i,a,o,r,y,l,s,c,d,E,P,k,h,z,p,F,M,N,I,m].map((e=>e.default)).filter(Boolean)},3781:(e,t,n)=>{n.d(t,{U:()=>i});const i=JSON.parse('{"article":{"/":{"path":"/article/","indexes":[0,6,12,7,13,18,19,1,2,3,4,5,20,21,8,9,10,11]},"/en/":{"path":"/en/article/","indexes":[22,14,17,15,16]}},"star":{"/":{"path":"/star/","indexes":[0]},"/en/":{"path":"/en/star/","indexes":[]}},"timeline":{"/":{"path":"/timeline/","indexes":[6,12,7,13,18,19,1,2,3,4,5,20,21,8,9,10,11,0]},"/en/":{"path":"/en/timeline/","indexes":[22,14,17,15,16]}}}')},4776:(e,t,n)=>{n.d(t,{M:()=>i});const i=JSON.parse('["/demo/page.html","/demo/","/demo/disable.html","/demo/encrypt.html","/demo/layout.html","/demo/markdown.html","/notes/","/zh/notes/","/posts/flashattention.html","/zh/posts/flashattention.html","/posts/cuda-tech-stack.html","/zh/posts/cuda-tech-stack.html","/projects/","/zh/projects/","/en/notes/","/en/posts/flashattention.html","/en/posts/cuda-tech-stack.html","/en/projects/","/intro.html","/about/","/zh/intro.html","/zh/about/","/en/intro.html"]')},4923:(e,t,n)=>{},6653:(e,t,n)=>{n.d(t,{K:()=>i});const i=JSON.parse('{"encrypt":{"config":{"/demo/encrypt.html":{"tokens":["$2b$10$y8CJxrn1EQlWahm44PpXHuW.9EbQ1f39KxBn8DWEIPXFINpa.FREm"],"hint":"Password: 1234"},"/en/demo/encrypt.html":{"tokens":["$2b$10$lt8rnWvE6UIxMeo7r.qChOBfqS.h4nYhnzhVtcrvGgXGF2duZuOYy"],"hint":"Password: 1234"}}},"author":{"name":"GYQ","url":"https://github.com/your-username"},"logo":"https://theme-hope-assets.vuejs.press/logo.svg","repo":"your-username/your-repo","docsDir":"src","blog":{"medias":{"GitHub":"https://github.com/your-username","Email":"mailto:your-email@example.com","BiliBili":"https://space.bilibili.com/your-id","Zhihu":"https://www.zhihu.com/people/your-id"}},"locales":{"/":{"lang":"zh-CN","navbarLocales":{"langName":"简体中文","selectLangAriaLabel":"选择语言"},"metaLocales":{"author":"作者","date":"写作日期","origin":"原创","views":"访问量","category":"分类","tag":"标签","readingTime":"阅读时间","words":"字数","toc":"此页内容","prev":"上一页","next":"下一页","contributors":"贡献者","editLink":"在 GitHub 上编辑此页","print":"打印"},"blogLocales":{"article":"文章","articleList":"文章列表","category":"分类","tag":"标签","timeline":"时间轴","timelineTitle":"昨日不在","all":"全部","intro":"个人介绍","star":"星标","empty":"$text 为空"},"paginationLocales":{"prev":"上一页","next":"下一页","navigate":"跳转到","action":"前往","errorText":"请输入 1 到 $page 之前的页码！"},"outlookLocales":{"themeColor":"主题色","darkmode":"外观","fullscreen":"全屏"},"encryptLocales":{"iconLabel":"文章已加密","placeholder":"输入密码","remember":"记住密码","errorHint":"请输入正确的密码"},"routeLocales":{"skipToContent":"跳至主要內容","notFoundTitle":"页面不存在","notFoundMsg":["这里什么也没有","我们是怎么来到这儿的？","这 是 四 零 四 !","看起来你访问了一个失效的链接"],"back":"返回上一页","home":"带我回家"},"navbar":["/zh/",{"text":"学习笔记","icon":"folder-open","link":"/zh/notes/"},{"text":"项目实践","icon":"code","link":"/zh/projects/"},{"text":"博文","icon":"pen-to-square","prefix":"/zh/posts/","children":[{"text":"CUDA技术栈","icon":"pen-to-square","link":"cuda-tech-stack"},{"text":"Flashattention","icon":"pen-to-square","link":"flashattention"}]}],"sidebar":{"/zh/":["",{"text":"如何使用","icon":"laptop-code","prefix":"demo/","link":"demo/","children":"structure"},{"text":"文章","icon":"book","prefix":"posts/","children":"structure"},"intro",{"text":"幻灯片","icon":"person-chalkboard","link":"https://ecosystem.vuejs.press/zh/plugins/markdown/revealjs/demo.html"}]},"footer":"唯一","displayFooter":true,"blog":{"description":"一个前端开发者","intro":"/intro.html"}},"/en/":{"lang":"en-US","navbarLocales":{"langName":"English","selectLangAriaLabel":"Select language"},"metaLocales":{"author":"Author","date":"Writing Date","origin":"Original","views":"Page views","category":"Category","tag":"Tag","readingTime":"Reading Time","words":"Words","toc":"On This Page","prev":"Prev","next":"Next","contributors":"Contributors","editLink":"Edit this page on GitHub","print":"Print"},"blogLocales":{"article":"Articles","articleList":"Article List","category":"Category","tag":"Tag","timeline":"Timeline","timelineTitle":"Yesterday Once More!","all":"All","intro":"Personal Intro","star":"Star","empty":"No $text"},"paginationLocales":{"prev":"Prev","next":"Next","navigate":"Jump to","action":"Go","errorText":"Please enter a number between 1 and $page !"},"outlookLocales":{"themeColor":"Theme Color","darkmode":"Theme Mode","fullscreen":"Full Screen"},"encryptLocales":{"iconLabel":"Page Encrypted","placeholder":"Enter password","remember":"Remember password","errorHint":"Please enter the correct password!"},"routeLocales":{"skipToContent":"Skip to main content","notFoundTitle":"Page not found","notFoundMsg":["There’s nothing here.","How did we get here?","That’s a Four-Oh-Four.","Looks like we\'ve got some broken links."],"back":"Go back","home":"Take me home"},"navbar":["/en/",{"text":"Learning Notes","icon":"folder-open","link":"/en/notes/"},{"text":"Projects","icon":"code","link":"/en/projects/"},{"text":"Posts","icon":"pen-to-square","prefix":"/en/posts/","children":[{"text":"CUDA Technology Stack","icon":"pen-to-square","link":"cuda-tech-stack"},{"text":"Flashattention","icon":"pen-to-square","link":"flashattention"}]}],"sidebar":{"/en/":["",{"text":"Posts","icon":"book","prefix":"posts/","children":"structure"},{"text":"Learning Notes","icon":"folder-open","prefix":"notes/","link":"notes/","children":"structure"},{"text":"Projects","icon":"code","prefix":"projects/","link":"projects/","children":"structure"},"intro"]},"footer":"Default footer","displayFooter":true,"blog":{"description":"A FrontEnd programmer","intro":"/en/intro.html"}}}}')},8123:(e,t,n)=>{n.d(t,{v:()=>i});const i={"/zh/demo/":[],"/zh/posts/":["cuda-tech-stack","flashattention"],"/en/posts/":["cuda-tech-stack","flashattention"],"/en/notes/":[],"/en/projects/":[]}},8164:(e,t,n)=>{n.d(t,{J:()=>a,c:()=>i});const i=JSON.parse("{}"),a=Object.fromEntries([["/",{loader:()=>n.e(4470).then(n.bind(n,9908)),meta:{title:"博客主页",icon:"house"}}],["/intro.html",{loader:()=>n.e(3912).then(n.bind(n,3155)),meta:{date:1747123438e3,cover:"/assets/images/cover3.jpg",excerpt:"\n<p>将你的个人介绍和档案放置在此处。</p>\n",readingTime:{minutes:.08,words:23},title:"介绍页",icon:"circle-info",type:"article"}}],["/about/",{loader:()=>n.e(4240).then(n.bind(n,9238)),meta:{date:1747123438e3,excerpt:"<h2>个人简介</h2>\n<p>你好！我是高宇庆，一名热爱技术的软件工程师。我目前专注于高性能计算（HPC）和GPU编程领域，尤其对CUDA技术充满热情。</p>\n<h3>技术领域</h3>\n<ul>\n<li>高性能计算（HPC）</li>\n<li>CUDA GPU编程</li>\n<li>并行计算优化</li>\n<li>深度学习加速</li>\n</ul>\n<h3>教育背景</h3>\n<ul>\n<li>硕士：SUSTECH</li>\n<li>本科：TYUT</li>\n</ul>\n<h3>技术博客</h3>\n<p>我创建这个技术博客的目的是：</p>\n<ol>\n<li>记录学习过程中的心得体会</li>\n<li>分享HPC和CUDA编程相关的技术经验</li>\n<li>与志同道合的朋友交流学习</li>\n</ol>",readingTime:{minutes:.52,words:157},title:"关于我",icon:"profile",type:"article"}}],["/en/",{loader:()=>n.e(8476).then(n.bind(n,877)),meta:{title:"Blog Home",icon:"house"}}],["/en/intro.html",{loader:()=>n.e(8038).then(n.bind(n,2675)),meta:{date:1747127391e3,cover:"/assets/images/cover3.jpg",excerpt:"\n<p>Place your personal introduction and profile here.</p>\n",readingTime:{minutes:.05,words:14},title:"Introduction Page",icon:"circle-info",type:"article"}}],["/demo/",{loader:()=>n.e(3320).then(n.bind(n,5351)),meta:{date:1747123438e3,category:["Guide"],readingTime:{minutes:.04,words:12},title:"Features demo",icon:"laptop-code",type:"article"}}],["/demo/disable.html",{loader:()=>n.e(2756).then(n.bind(n,2411)),meta:{date:1747123438e3,category:["Guide"],tag:["disable"],excerpt:"<p>You can disable some function and layout on the page by setting the Frontmatter of the page.</p>\n",readingTime:{minutes:.28,words:83},title:"Disabling layout and features",icon:"gears",order:4,type:"article"}}],["/demo/encrypt.html",{loader:()=>n.e(2581).then(n.bind(n,1280)),meta:{date:1747123438e3,category:["Guide"],tag:["encryption"],isEncrypted:!0,readingTime:{minutes:.3,words:90},title:"Encryption Article",icon:"lock",type:"article"}}],["/demo/layout.html",{loader:()=>n.e(6216).then(n.bind(n,3553)),meta:{date:1747123438e3,category:["Guide"],tag:["Layout"],excerpt:'<p>The layout contains:</p>\n<ul>\n<li><a href="https://theme-hope.vuejs.press/guide/layout/navbar.html" target="_blank" rel="noopener noreferrer">Navbar</a></li>\n<li><a href="https://theme-hope.vuejs.press/guide/layout/sidebar.html" target="_blank" rel="noopener noreferrer">Sidebar</a></li>\n<li><a href="https://theme-hope.vuejs.press/guide/layout/footer.html" target="_blank" rel="noopener noreferrer">Footer</a></li>\n</ul>',readingTime:{minutes:.35,words:106},title:"Layout",icon:"object-group",order:2,type:"article"}}],["/demo/markdown.html",{loader:()=>n.e(8711).then(n.bind(n,4053)),meta:{date:1747123438e3,category:["Guide"],tag:["Markdown"],excerpt:"<p>VuePress basically generate pages from Markdown files. So you can use it to generate documentation or blog sites easily.</p>\n<p>You should create and write Markdown files, so that VuePress can convert them to different pages according to file structure.</p>\n",readingTime:{minutes:2.63,words:789},title:"Markdown Enhance",icon:"fa6-brands:markdown",order:2,type:"article"}}],["/demo/page.html",{loader:()=>n.e(645).then(n.bind(n,5397)),meta:{author:"Ms.Hope",date:15778368e5,category:["Guide"],tag:["Page config","Guide"],sticky:!0,excerpt:"<p>Content before <code>more</code> comment is regarded as page excerpt.</p>\n",readingTime:{minutes:1.14,words:341},title:"Page Config",icon:"file",order:3,type:"article"}}],["/interview/",{loader:()=>n.e(9858).then(n.bind(n,9092)),meta:{title:"八股文总结",icon:"book"}}],["/notes/",{loader:()=>n.e(1372).then(n.bind(n,8690)),meta:{date:1747125782e3,category:["笔记"],excerpt:'\n<p>这里收集了我的技术学习笔记和心得体会，包括各种技术栈的学习记录。</p>\n<h2>笔记列表</h2>\n<ul>\n<li><a href="/zh/posts/flashattention.html" target="_blank" rel="noopener noreferrer">Flashattention技术详解</a> - 高效注意力机制计算方法的详细解析</li>\n<li><a href="/zh/posts/cuda-tech-stack.html" target="_blank" rel="noopener noreferrer">CUDA技术栈</a> - CUDA并行计算平台及编程模型介绍</li>\n</ul>',readingTime:{minutes:.31,words:94},title:"学习笔记",icon:"folder-open",type:"article"}}],["/posts/cuda-tech-stack.html",{loader:()=>n.e(81).then(n.bind(n,3920)),meta:{date:17466624e5,category:["CUDA","笔记"],tag:["技术","GPU编程"],excerpt:"\n<h2>简介</h2>\n<p>CUDA（Compute Unified Device Architecture）是NVIDIA推出的并行计算平台和编程模型，它能够显著提升计算性能。本文将介绍CUDA技术栈的主要组成部分和开发工具。</p>\n<h2>核心组件</h2>\n<h3>1. CUDA Runtime API</h3>\n<ul>\n<li>高级API接口</li>\n<li>设备管理</li>\n<li>内存管理</li>\n<li>流和事件处理</li>\n</ul>\n<h3>2. CUDA Driver API</h3>\n<ul>\n<li>底层API接口</li>\n<li>更灵活的控制</li>\n<li>上下文管理</li>\n</ul>",readingTime:{minutes:.98,words:295},title:"CUDA技术栈",type:"article"}}],["/posts/flashattention.html",{loader:()=>n.e(6048).then(n.bind(n,8559)),meta:{date:17468352e5,category:["机器学习","深度学习","笔记"],tag:["注意力机制","GPU优化","大模型","算法优化"],cover:"/assets/images/cover3.jpg",isOriginal:!0,excerpt:"\n<h2>简介</h2>\n<p>Flashattention是一种高效的注意力机制计算方法，由斯坦福大学研究团队在2022年提出。它通过优化GPU内存访问模式，显著提高了Transformer模型中注意力计算的速度并降低了内存使用。作为大模型训练和推理的关键优化技术，Flashattention已被广泛应用于各种大型语言模型中。</p>\n",readingTime:{minutes:1.98,words:593},title:"Flashattention",type:"article"}}],["/projects/",{loader:()=>n.e(3705).then(n.bind(n,2520)),meta:{date:1747125782e3,category:["项目"],excerpt:'\n<h2>项目概述</h2>\n<p>本项目实现了一个基于CUDA的图像处理系统，能够对高分辨率图像进行实时处理，包括滤波、边缘检测、图像增强等功能。系统充分利用GPU并行计算能力，相比CPU实现提速10-50倍。</p>\n<h2>技术栈</h2>\n<ul>\n<li>CUDA C/C++</li>\n<li>OpenCV</li>\n<li>CMake</li>\n<li>Python (用于UI界面)</li>\n</ul>\n<h2>系统架构</h2>\n<figure><img src="/Notes/images/project-arch.png" alt="系统架构图" tabindex="0" loading="lazy"><figcaption>系统架构图</figcaption></figure>',readingTime:{minutes:1.33,words:398},title:"项目实践",icon:"code",type:"article"}}],["/zh/",{loader:()=>n.e(433).then(n.bind(n,5762)),meta:{title:"博客主页",icon:"house"}}],["/zh/intro.html",{loader:()=>n.e(787).then(n.bind(n,6980)),meta:{date:1747123438e3,cover:"/assets/images/cover3.jpg",excerpt:"\n<p>将你的个人介绍和档案放置在此处。</p>\n",readingTime:{minutes:.08,words:23},title:"介绍页",icon:"circle-info",type:"article"}}],["/en/notes/",{loader:()=>n.e(7282).then(n.bind(n,5695)),meta:{date:1747127391e3,category:["Notes"],excerpt:'\n<p>Here I collect my technical learning notes and insights, including learning records of various technology stacks.</p>\n<h2>Notes List</h2>\n<ul>\n<li><a href="/en/posts/flashattention.html" target="_blank" rel="noopener noreferrer">Flashattention Technical Details</a> - Detailed analysis of efficient attention mechanism calculation methods</li>\n<li><a href="/en/posts/cuda-tech-stack.html" target="_blank" rel="noopener noreferrer">CUDA Technology Stack</a> - Introduction to CUDA parallel computing platform and programming model</li>\n</ul>',readingTime:{minutes:.19,words:57},title:"Learning Notes",icon:"folder-open",type:"article"}}],["/en/posts/cuda-tech-stack.html",{loader:()=>n.e(7063).then(n.bind(n,3794)),meta:{date:17466624e5,category:["CUDA","Notes"],tag:["Technology","GPU Programming"],excerpt:"\n<h2>Introduction</h2>\n<p>CUDA (Compute Unified Device Architecture) is a parallel computing platform and programming model launched by NVIDIA that can significantly enhance computational performance. This article introduces the main components of the CUDA technology stack and development tools.</p>",readingTime:{minutes:.61,words:184},title:"CUDA Technology Stack",type:"article"}}],["/en/posts/flashattention.html",{loader:()=>n.e(3874).then(n.bind(n,8329)),meta:{date:17468352e5,category:["Machine Learning","Deep Learning","Notes"],tag:["Attention Mechanism","GPU Optimization","Large Models","Algorithm Optimization"],cover:"/assets/images/cover3.jpg",isOriginal:!0,excerpt:"\n<h2>Introduction</h2>\n<p>Flashattention is an efficient attention mechanism calculation method proposed by a Stanford University research team in 2022. It significantly improves the speed of attention calculations in Transformer models and reduces memory usage by optimizing GPU memory access patterns. As a key optimization technology for large model training and inference, Flashattention has been widely applied in various large language models.</p>\n",readingTime:{minutes:1.26,words:377},title:"Flashattention",type:"article"}}],["/en/projects/",{loader:()=>n.e(6795).then(n.bind(n,8760)),meta:{date:1747127391e3,category:["Project"],excerpt:"\n<h2>Project Overview</h2>\n<p>This project implements a CUDA-based image processing system capable of real-time processing of high-resolution images, including filtering, edge detection, image enhancement, and other functions. The system fully utilizes GPU parallel computing capabilities, achieving 10-50 times speedup compared to CPU implementations.</p>",readingTime:{minutes:.77,words:231},title:"Projects",icon:"code",type:"article"}}],["/zh/about/",{loader:()=>n.e(9571).then(n.bind(n,9789)),meta:{date:1747123438e3,excerpt:"<h2>个人简介</h2>\n<p>你好！我是高宇庆，一名热爱技术的软件工程师。我目前专注于高性能计算（HPC）和GPU编程领域，尤其对CUDA技术充满热情。</p>\n<h3>技术领域</h3>\n<ul>\n<li>高性能计算（HPC）</li>\n<li>CUDA GPU编程</li>\n<li>并行计算优化</li>\n<li>深度学习加速</li>\n</ul>\n<h3>教育背景</h3>\n<ul>\n<li>硕士：SUSTECH</li>\n<li>本科：TYUT</li>\n</ul>\n<h3>技术博客</h3>\n<p>我创建这个技术博客的目的是：</p>\n<ol>\n<li>记录学习过程中的心得体会</li>\n<li>分享HPC和CUDA编程相关的技术经验</li>\n<li>与志同道合的朋友交流学习</li>\n</ol>",readingTime:{minutes:.52,words:157},title:"关于我",icon:"profile",type:"article"}}],["/zh/interview/",{loader:()=>n.e(3637).then(n.bind(n,3588)),meta:{title:"八股文总结",icon:"book"}}],["/zh/notes/",{loader:()=>n.e(2043).then(n.bind(n,8833)),meta:{date:1747125782e3,category:["笔记"],excerpt:'\n<p>这里收集了我的技术学习笔记和心得体会，包括各种技术栈的学习记录。</p>\n<h2>笔记列表</h2>\n<ul>\n<li><a href="/zh/posts/flashattention.html" target="_blank" rel="noopener noreferrer">Flashattention技术详解</a> - 高效注意力机制计算方法的详细解析</li>\n<li><a href="/zh/posts/cuda-tech-stack.html" target="_blank" rel="noopener noreferrer">CUDA技术栈</a> - CUDA并行计算平台及编程模型介绍</li>\n</ul>',readingTime:{minutes:.31,words:94},title:"学习笔记",icon:"folder-open",type:"article"}}],["/zh/posts/cuda-tech-stack.html",{loader:()=>n.e(2386).then(n.bind(n,4007)),meta:{date:17466624e5,category:["CUDA","笔记"],tag:["技术","GPU编程"],excerpt:"\n<h2>简介</h2>\n<p>CUDA（Compute Unified Device Architecture）是NVIDIA推出的并行计算平台和编程模型，它能够显著提升计算性能。本文将介绍CUDA技术栈的主要组成部分和开发工具。</p>\n<h2>核心组件</h2>\n<h3>1. CUDA Runtime API</h3>\n<ul>\n<li>高级API接口</li>\n<li>设备管理</li>\n<li>内存管理</li>\n<li>流和事件处理</li>\n</ul>\n<h3>2. CUDA Driver API</h3>\n<ul>\n<li>底层API接口</li>\n<li>更灵活的控制</li>\n<li>上下文管理</li>\n</ul>",readingTime:{minutes:.98,words:295},title:"CUDA技术栈",type:"article"}}],["/zh/posts/flashattention.html",{loader:()=>n.e(609).then(n.bind(n,568)),meta:{date:17468352e5,category:["机器学习","深度学习","笔记"],tag:["注意力机制","GPU优化","大模型","算法优化"],cover:"/assets/images/cover3.jpg",isOriginal:!0,excerpt:"\n<h2>简介</h2>\n<p>Flashattention是一种高效的注意力机制计算方法，由斯坦福大学研究团队在2022年提出。它通过优化GPU内存访问模式，显著提高了Transformer模型中注意力计算的速度并降低了内存使用。作为大模型训练和推理的关键优化技术，Flashattention已被广泛应用于各种大型语言模型中。</p>\n",readingTime:{minutes:1.98,words:593},title:"Flashattention",type:"article"}}],["/zh/projects/",{loader:()=>n.e(3844).then(n.bind(n,5562)),meta:{date:1747125782e3,category:["项目"],excerpt:'\n<h2>项目概述</h2>\n<p>本项目实现了一个基于CUDA的图像处理系统，能够对高分辨率图像进行实时处理，包括滤波、边缘检测、图像增强等功能。系统充分利用GPU并行计算能力，相比CPU实现提速10-50倍。</p>\n<h2>技术栈</h2>\n<ul>\n<li>CUDA C/C++</li>\n<li>OpenCV</li>\n<li>CMake</li>\n<li>Python (用于UI界面)</li>\n</ul>\n<h2>系统架构</h2>\n<figure><img src="/Notes/images/project-arch.png" alt="系统架构图" tabindex="0" loading="lazy"><figcaption>系统架构图</figcaption></figure>',readingTime:{minutes:1.33,words:398},title:"项目实践",icon:"code",type:"article"}}],["/404.html",{loader:()=>n.e(7490).then(n.bind(n,1489)),meta:{title:""}}],["/posts/",{loader:()=>n.e(8666).then(n.bind(n,8063)),meta:{title:"Posts"}}],["/en/posts/",{loader:()=>n.e(9928).then(n.bind(n,1396)),meta:{title:"Posts"}}],["/zh/posts/",{loader:()=>n.e(9773).then(n.bind(n,2269)),meta:{title:"Posts"}}],["/category/",{loader:()=>n.e(3583).then(n.bind(n,3233)),meta:{title:"分类",index:!1}}],["/category/guide/",{loader:()=>n.e(3468).then(n.bind(n,6487)),meta:{title:"Guide 分类",index:!1}}],["/category/%E7%AC%94%E8%AE%B0/",{loader:()=>n.e(7632).then(n.bind(n,392)),meta:{title:"笔记 分类",index:!1}}],["/category/cuda/",{loader:()=>n.e(239).then(n.bind(n,386)),meta:{title:"CUDA 分类",index:!1}}],["/category/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/",{loader:()=>n.e(8400).then(n.bind(n,8943)),meta:{title:"机器学习 分类",index:!1}}],["/category/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/",{loader:()=>n.e(4877).then(n.bind(n,6090)),meta:{title:"深度学习 分类",index:!1}}],["/category/%E9%A1%B9%E7%9B%AE/",{loader:()=>n.e(5459).then(n.bind(n,8260)),meta:{title:"项目 分类",index:!1}}],["/en/category/",{loader:()=>n.e(2357).then(n.bind(n,1204)),meta:{title:"Category",index:!1}}],["/en/category/notes/",{loader:()=>n.e(4455).then(n.bind(n,865)),meta:{title:"Notes Category",index:!1}}],["/en/category/cuda/",{loader:()=>n.e(137).then(n.bind(n,7931)),meta:{title:"CUDA Category",index:!1}}],["/en/category/machine-learning/",{loader:()=>n.e(3072).then(n.bind(n,9256)),meta:{title:"Machine Learning Category",index:!1}}],["/en/category/deep-learning/",{loader:()=>n.e(4429).then(n.bind(n,1406)),meta:{title:"Deep Learning Category",index:!1}}],["/en/category/project/",{loader:()=>n.e(6823).then(n.bind(n,4324)),meta:{title:"Project Category",index:!1}}],["/tag/",{loader:()=>n.e(1797).then(n.bind(n,951)),meta:{title:"标签",index:!1}}],["/tag/disable/",{loader:()=>n.e(702).then(n.bind(n,6216)),meta:{title:"标签: disable",index:!1}}],["/tag/encryption/",{loader:()=>n.e(6803).then(n.bind(n,5476)),meta:{title:"标签: encryption",index:!1}}],["/tag/layout/",{loader:()=>n.e(1180).then(n.bind(n,6413)),meta:{title:"标签: Layout",index:!1}}],["/tag/markdown/",{loader:()=>n.e(7931).then(n.bind(n,8216)),meta:{title:"标签: Markdown",index:!1}}],["/tag/page-config/",{loader:()=>n.e(8782).then(n.bind(n,5844)),meta:{title:"标签: Page config",index:!1}}],["/tag/guide/",{loader:()=>n.e(6210).then(n.bind(n,2351)),meta:{title:"标签: Guide",index:!1}}],["/tag/%E6%8A%80%E6%9C%AF/",{loader:()=>n.e(3111).then(n.bind(n,7472)),meta:{title:"标签: 技术",index:!1}}],["/tag/gpu%E7%BC%96%E7%A8%8B/",{loader:()=>n.e(27).then(n.bind(n,6443)),meta:{title:"标签: GPU编程",index:!1}}],["/tag/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/",{loader:()=>n.e(256).then(n.bind(n,8331)),meta:{title:"标签: 注意力机制",index:!1}}],["/tag/gpu%E4%BC%98%E5%8C%96/",{loader:()=>n.e(814).then(n.bind(n,3226)),meta:{title:"标签: GPU优化",index:!1}}],["/tag/%E5%A4%A7%E6%A8%A1%E5%9E%8B/",{loader:()=>n.e(7655).then(n.bind(n,9417)),meta:{title:"标签: 大模型",index:!1}}],["/tag/%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96/",{loader:()=>n.e(104).then(n.bind(n,6377)),meta:{title:"标签: 算法优化",index:!1}}],["/en/tag/",{loader:()=>n.e(9603).then(n.bind(n,2760)),meta:{title:"Tag",index:!1}}],["/en/tag/technology/",{loader:()=>n.e(8018).then(n.bind(n,9853)),meta:{title:"Tag: Technology",index:!1}}],["/en/tag/gpu-programming/",{loader:()=>n.e(3550).then(n.bind(n,7417)),meta:{title:"Tag: GPU Programming",index:!1}}],["/en/tag/attention-mechanism/",{loader:()=>n.e(6450).then(n.bind(n,8183)),meta:{title:"Tag: Attention Mechanism",index:!1}}],["/en/tag/gpu-optimization/",{loader:()=>n.e(8788).then(n.bind(n,883)),meta:{title:"Tag: GPU Optimization",index:!1}}],["/en/tag/large-models/",{loader:()=>n.e(7024).then(n.bind(n,9768)),meta:{title:"Tag: Large Models",index:!1}}],["/en/tag/algorithm-optimization/",{loader:()=>n.e(2913).then(n.bind(n,2347)),meta:{title:"Tag: Algorithm Optimization",index:!1}}],["/article/",{loader:()=>n.e(7511).then(n.bind(n,2772)),meta:{title:"文章",index:!1}}],["/en/article/",{loader:()=>n.e(6337).then(n.bind(n,2244)),meta:{title:"Articles",index:!1}}],["/star/",{loader:()=>n.e(7199).then(n.bind(n,353)),meta:{title:"星标",index:!1}}],["/en/star/",{loader:()=>n.e(1589).then(n.bind(n,9203)),meta:{title:"Star",index:!1}}],["/timeline/",{loader:()=>n.e(5464).then(n.bind(n,4695)),meta:{title:"时间轴",index:!1}}],["/en/timeline/",{loader:()=>n.e(5314).then(n.bind(n,855)),meta:{title:"Timeline",index:!1}}]])},8761:(e,t,n)=>{n.d(t,{U:()=>i});const i=JSON.parse('{"base":"/Notes/","lang":"en-US","title":"","description":"","head":[],"locales":{"/":{"lang":"zh-CN","title":"GYQ的博客","description":"个人技术博客与学习笔记"},"/en/":{"lang":"en-US","title":"GYQ\'s Blog","description":"Personal technical blog and learning notes"}}}')}},e=>{e.O(0,[5587,2047],(()=>e(e.s=8731))),e.O()}]);